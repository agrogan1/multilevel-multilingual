[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Multilevel Multilingual",
    "section": "",
    "text": "1 Multilevel Multilingual",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Multilevel Multilingual</span>"
    ]
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Multilevel Multilingual",
    "section": "1.1 Introduction",
    "text": "1.1 Introduction\nBelow, I describe the use of Stata, R, and Julia to estimate multilevel models.\n\n\n\n\n\n\nResults Will Vary Somewhat\n\n\n\nEstimating multilevel models is a complex endeavor. The software details of how this is accomplished are beyond the purview of this book. Suffice it to say that across different software packages there will be differences in estimation routines, resulting in some numerical differences in the results provided by different software packages. Substantively speaking, however, results should agree across software.\n\n\n\n\n\n\n\n\nMulti-Line Commands\n\n\n\nSometimes I have written commands out over multiple lines. I have done this for especially long commands, but have also sometimes done this simply for the sake of clarity. The different software packages have different approaches to multi-line commands.\n\nBy default, Stata ends a command at the end of a line. If you are going to write a multi-line command you should use the /// line continuation characters.\nR is the software that most naturally can be written using multiple lines, as R commands are usually clearly encased in parentheses (()) or continued with + signs.\nLike Stata, Julia expects commands to end at the end of a line. If you are going to write a mult-line command, all commands except for the last line should end in a character that clearly indicates continuation, like a + sign. An alternative is to encase the entire Julia command in an outer set of parentheses (()).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Multilevel Multilingual</span>"
    ]
  },
  {
    "objectID": "index.html#sec-data",
    "href": "index.html#sec-data",
    "title": "Multilevel Multilingual",
    "section": "1.2 The Data",
    "text": "1.2 The Data\nThe examples use the simulated_multilevel_data.dta file from Multilevel Thinking. Here is a direct link to download the data.\n\n\n\n\nTable 1.1: Sample of Simulated Multilevel Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncountry\nHDI\nfamily\nid\ngroup\nphysical_punishment\nwarmth\noutcome\n\n\n\n\n1\n69\n1\n1.1\n2\n2\n3\n59.18\n\n\n1\n69\n2\n1.2\n2\n4\n0\n61.54\n\n\n1\n69\n3\n1.3\n1\n4\n4\n51.87\n\n\n1\n69\n4\n1.4\n2\n0\n6\n51.71\n\n\n1\n69\n5\n1.5\n2\n3\n2\n55.88\n\n\n1\n69\n6\n1.6\n1\n5\n3\n60.78",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Multilevel Multilingual</span>"
    ]
  },
  {
    "objectID": "index.html#sec-syntax",
    "href": "index.html#sec-syntax",
    "title": "Multilevel Multilingual",
    "section": "1.3 An Introduction To Equations and Syntax",
    "text": "1.3 An Introduction To Equations and Syntax\nTo explain statistical syntax for each software, I consider the general case of a multilevel model with dependent variable y, independent variables x and z, clustering variable group, and a random slope for x. i is the index for the person, while j is the index for the group.\n\\[y = \\beta_0 + \\beta_1 x_{ij} + \\beta_2 z_{ij} + u_{0j} + u_{1j} \\times x_{ij} + e_{ij} \\tag{1.1}\\]\n\nStataRJulia\n\n\nIn Stata mixed, the syntax for a multilevel model of the form described in Equation 1.1 is:\n\nmixed y x || group: x\n\n\n\nIn R lme4, the general syntax for a multilevel model of the form described in Equation 1.1 is:\n\nlibrary(lme4)\n\nlmer(y ~ x + z + (1 + x || group), data = ...)\n\n\n\nIn Julia MixedModels, the general syntax for a multilevel model of the form described in Equation 1.1 is:\n\nusing MixedModels\n\nfit(MixedModel, @formula(y ~ x + z + (1 + x | group)), data)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Multilevel Multilingual</span>"
    ]
  },
  {
    "objectID": "descriptives-multilingual.html",
    "href": "descriptives-multilingual.html",
    "title": "2  Descriptive Statistics",
    "section": "",
    "text": "2.1 Descriptive Statistics",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "descriptives-multilingual.html#descriptive-statistics",
    "href": "descriptives-multilingual.html#descriptive-statistics",
    "title": "2  Descriptive Statistics",
    "section": "",
    "text": "StataRJulia\n\n\n\n\nuse simulated_multilevel_data.dta // use data\n\nWe use summarize for continuous variables, and tabulate for categorical variables.\n\n\nsummarize outcome warmth physical_punishment HDI\n\ntabulate group\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n     outcome |      3,000    53.46757     6.65179   33.39014   76.75101\n      warmth |      3,000    3.524333    1.889956          0          7\nphysical_p~t |      3,000    2.494667    1.380075          0          5\n         HDI |      3,000    64.76667    17.24562         33         87\n\n\n  arbitrary |\n      group |\n   variable |      Freq.     Percent        Cum.\n------------+-----------------------------------\n          1 |      1,507       50.23       50.23\n          2 |      1,493       49.77      100.00\n------------+-----------------------------------\n      Total |      3,000      100.00\n\n\n\n\n\nlibrary(haven) # read data in Stata format\n\ndf &lt;- read_dta(\"simulated_multilevel_data.dta\")\n\nR’s descriptive statistics functions rely heavily on whether a variable is a numeric variable, or a factor variable. Below, I convert two variables to factors (factor) before using summary1 to generate descriptive statistics.\n\ndf$country &lt;- factor(df$country)\n\ndf$group &lt;- factor(df$group)\n\nsummary(df)\n\n    country          HDI            family            id            group   \n 1      : 100   Min.   :33.00   Min.   :  1.00   Length:3000        1:1507  \n 2      : 100   1st Qu.:53.00   1st Qu.: 25.75   Class :character   2:1493  \n 3      : 100   Median :70.00   Median : 50.50   Mode  :character           \n 4      : 100   Mean   :64.77   Mean   : 50.50                              \n 5      : 100   3rd Qu.:81.00   3rd Qu.: 75.25                              \n 6      : 100   Max.   :87.00   Max.   :100.00                              \n (Other):2400                                                               \n physical_punishment     warmth         outcome     \n Min.   :0.000       Min.   :0.000   Min.   :33.39  \n 1st Qu.:2.000       1st Qu.:2.000   1st Qu.:48.78  \n Median :3.000       Median :4.000   Median :53.64  \n Mean   :2.495       Mean   :3.524   Mean   :53.47  \n 3rd Qu.:3.250       3rd Qu.:5.000   3rd Qu.:58.06  \n Max.   :5.000       Max.   :7.000   Max.   :76.75  \n                                                    \n\n\n\n\n\nusing Tables, MixedModels, MixedModelsExtras, StatFiles, DataFrames, CategoricalArrays, DataFramesMeta\n\ndf = DataFrame(load(\"simulated_multilevel_data.dta\"))\n\nSimilarly to R, Julia relies on the idea of variable type. I use transform to convert the appropriate variables to categorical variables.\n\n@transform!(df, :country = categorical(:country))\n\n@transform!(df, :group = categorical(:group))\n\n\n\ndescribe(df) # descriptive statistics\n\n8×7 DataFrame\n Row │ variable             mean     min      median   max     nmissing  eltyp ⋯\n     │ Symbol               Union…   Any      Union…   Any     Int64     Union ⋯\n─────┼──────────────────────────────────────────────────────────────────────────\n   1 │ country                       1.0               30.0           0  Union ⋯\n   2 │ HDI                  64.7667  33.0     70.0     87.0           0  Union\n   3 │ family               50.5     1.0      50.5     100.0          0  Union\n   4 │ id                            1.1               9.99           0  Union\n   5 │ group                         1.0               2.0            0  Union ⋯\n   6 │ physical_punishment  2.49467  0.0      3.0      5.0            0  Union\n   7 │ warmth               3.52433  0.0      4.0      7.0            0  Union\n   8 │ outcome              53.4676  33.3901  53.6426  76.751         0  Union\n                                                                1 column omitted",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "descriptives-multilingual.html#footnotes",
    "href": "descriptives-multilingual.html#footnotes",
    "title": "2  Descriptive Statistics",
    "section": "",
    "text": "skimr is an excellent new alternative library for generating descriptive statistics in R.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "unconditional-multilingual.html",
    "href": "unconditional-multilingual.html",
    "title": "3  Unconditional Model",
    "section": "",
    "text": "3.1 The Equation\n\\[\\text{outcome}_{ij}= \\beta_0 + u_{0j} + e_{ij} \\tag{3.1}\\]\nThe Intraclass Correlation Coefficient (ICC) is given by:\n\\[\\text{ICC} = \\frac{var(u_{0j})}{var(u_{0j}) + var(e_{ij})} \\tag{3.2}\\]\nIn a two level multilevel model, the ICC provides a measure of the amount of variation attributable to Level 2.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Unconditional Model</span>"
    ]
  },
  {
    "objectID": "unconditional-multilingual.html#run-models",
    "href": "unconditional-multilingual.html#run-models",
    "title": "3  Unconditional Model",
    "section": "3.2 Run Models",
    "text": "3.2 Run Models\n\nStataRJulia\n\n\n\n\nuse simulated_multilevel_data.dta // use data\n\n\n\nmixed outcome || country: // unconditional model\n  \n\nPerforming EM optimization ...\n\nPerforming gradient-based optimization: \nIteration 0:  Log likelihood = -9856.1548  \nIteration 1:  Log likelihood = -9856.1548  \n\nComputing standard errors ...\n\nMixed-effects ML regression                           Number of obs    = 3,000\nGroup variable: country                               Number of groups =    30\n                                                      Obs per group:\n                                                                   min =   100\n                                                                   avg = 100.0\n                                                                   max =   100\n                                                      Wald chi2(0)     =     .\nLog likelihood = -9856.1548                           Prob &gt; chi2      =     .\n\n------------------------------------------------------------------------------\n     outcome | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n       _cons |   53.46757   .3539097   151.08   0.000     52.77392    54.16122\n------------------------------------------------------------------------------\n\n------------------------------------------------------------------------------\n  Random-effects parameters  |   Estimate   Std. err.     [95% conf. interval]\n-----------------------------+------------------------------------------------\ncountry: Identity            |\n                  var(_cons) |   3.348734   .9702594      1.897816    5.908906\n-----------------------------+------------------------------------------------\n               var(Residual) |   40.88284   1.060908       38.8555    43.01597\n------------------------------------------------------------------------------\nLR test vs. linear model: chibar2(01) = 169.64        Prob &gt;= chibar2 = 0.0000\n\n\n\n  \nestat icc // ICC\n\nIntraclass correlation\n\n------------------------------------------------------------------------------\n                       Level |        ICC   Std. err.     [95% conf. interval]\n-----------------------------+------------------------------------------------\n                     country |   .0757091   .0203761      .0442419    .1265931\n------------------------------------------------------------------------------\n\n\n\n\n\nlibrary(haven)\n\ndf &lt;- read_dta(\"simulated_multilevel_data.dta\")\n\n\nlibrary(lme4) # estimate multilevel models\n\nfit0 &lt;- lmer(outcome ~ (1 | country),\n             data = df) # unconditional model\n\nsummary(fit0)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: outcome ~ (1 | country)\n   Data: df\n\nREML criterion at convergence: 19712.5\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.97650 -0.68006  0.00936  0.67580  3.03510 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n country  (Intercept)  3.478   1.865   \n Residual             40.883   6.394   \nNumber of obs: 3000, groups:  country, 30\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)    53.47       0.36   148.5\n\n\n\nlibrary(performance)\n\nperformance::icc(fit0) # ICC\n\n# Intraclass Correlation Coefficient\n\n    Adjusted ICC: 0.078\n  Unadjusted ICC: 0.078\n\n\n\n\n\nusing Tables, MixedModels, MixedModelsExtras, \nStatFiles, DataFrames, CategoricalArrays, DataFramesMeta\n\ndf = DataFrame(load(\"simulated_multilevel_data.dta\"))\n\n\n@transform!(df, :country = categorical(:country))\n\n\n\nm0 = fit(MixedModel, \n         @formula(outcome ~ (1 | country)), df) # unconditional model\n\nLinear mixed model fit by maximum likelihood\n outcome ~ 1 + (1 | country)\n   logLik   -2 logLik     AIC       AICc        BIC    \n -9856.1548 19712.3097 19718.3097 19718.3177 19736.3288\n\nVariance components:\n            Column   Variance Std.Dev.\ncountry  (Intercept)   3.34871 1.82995\nResidual              40.88285 6.39397\n Number of obs: 3000; levels of grouping factors: 30\n\n  Fixed-effects parameters:\n──────────────────────────────────────────────────\n               Coef.  Std. Error       z  Pr(&gt;|z|)\n──────────────────────────────────────────────────\n(Intercept)  53.4676    0.353908  151.08    &lt;1e-99\n──────────────────────────────────────────────────\n\n\n\n\nicc(m0) # ICC\n\n0.07570852291396266",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Unconditional Model</span>"
    ]
  },
  {
    "objectID": "cross-sectional-multilingual.html",
    "href": "cross-sectional-multilingual.html",
    "title": "4  Cross Sectional Multilevel Models",
    "section": "",
    "text": "4.1 The Equation\nRecall the general model of Equation 1.1, and the syntax outlined in Section 1.3. Below in Equation 4.1, we consider a more substantive example.\n\\[\\text{outcome}_{ij}= \\beta_0 + \\beta_1 \\text{warmth}_{ij} + \\beta_2 \\text{physical punishment}_{ij} + \\\\ \\beta_3 \\text{group}_{ij} + \\beta_4 \\text{HDI}_{ij} + \\\\ u_{0j} + u_{1j} \\times \\text{warmth}_{ij} + e_{ij} \\tag{4.1}\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cross Sectional Multilevel Models</span>"
    ]
  },
  {
    "objectID": "cross-sectional-multilingual.html#the-equation",
    "href": "cross-sectional-multilingual.html#the-equation",
    "title": "4  Cross Sectional Multilevel Models",
    "section": "",
    "text": "Run Models\n\n\n\n4.1.1 Stata\n\n4.1.1.1 Get The Data\n\n\nuse simulated_multilevel_data.dta\n\n\n\n4.1.1.2 Graph\n\ntwoway scatter outcome warmth, ///\n  xtitle(\"warmth\") ytitle(\"outcome\") ///\n  title(\"Outcome by Parental Warmth\") \n\nquietly graph export scatter.png, replace\n\n\n\n\n\n\n\nFigure 4.1: Outcome by Parental Warmth (Stata)\n\n\n\n\n\n4.1.1.3 Run The Model\n\n\nmixed outcome warmth physical_punishment group HDI || country: warmth\n\nPerforming EM optimization ...\n\nPerforming gradient-based optimization: \nIteration 0:  Log likelihood =  -9668.198  \nIteration 1:  Log likelihood = -9667.9551  \nIteration 2:  Log likelihood = -9667.9534  \nIteration 3:  Log likelihood = -9667.9533  \nIteration 4:  Log likelihood = -9667.9532  \n\nComputing standard errors ...\n\nMixed-effects ML regression                          Number of obs    =  3,000\nGroup variable: country                              Number of groups =     30\n                                                     Obs per group:\n                                                                  min =    100\n                                                                  avg =  100.0\n                                                                  max =    100\n                                                     Wald chi2(4)     = 401.26\nLog likelihood = -9667.9532                          Prob &gt; chi2      = 0.0000\n\n-------------------------------------------------------------------------------------\n            outcome | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n--------------------+----------------------------------------------------------------\n             warmth |   .9616447   .0581825    16.53   0.000     .8476091     1.07568\nphysical_punishment |  -.8453802   .0798155   -10.59   0.000    -1.001816   -.6889448\n              group |   1.084344   .2200539     4.93   0.000     .6530461    1.515642\n                HDI |    .010557   .0204522     0.52   0.606    -.0295286    .0506426\n              _cons |   49.87963   1.436612    34.72   0.000     47.06392    52.69534\n-------------------------------------------------------------------------------------\n\n------------------------------------------------------------------------------\n  Random-effects parameters  |   Estimate   Std. err.     [95% conf. interval]\n-----------------------------+------------------------------------------------\ncountry: Independent         |\n                 var(warmth) |   1.83e-06   .0000173      1.76e-14    190.9774\n                  var(_cons) |   3.370262   .9633726      1.924651    5.901676\n-----------------------------+------------------------------------------------\n               var(Residual) |   36.01906   .9346936      34.23291    37.89842\n------------------------------------------------------------------------------\nLR test vs. linear model: chi2(2) = 198.01                Prob &gt; chi2 = 0.0000\n\nNote: LR test is conservative and provided only for reference.\n\n\n\n\n\n4.1.2 R\n\n4.1.2.1 Get The Data\n\nlibrary(haven)\n\ndf &lt;- read_dta(\"simulated_multilevel_data.dta\")\n\n\n\n4.1.2.2 Graph\n\nlibrary(ggplot2)\n\nggplot(df,\n       aes(x = warmth,\n           y = outcome)) +\n  geom_point() +\n  labs(title = \"Outcome by Parental Warmth\")\n\n\n\n\n\n\n\nFigure 4.2: Outcome by Parental Warmth (R)\n\n\n\n\n\n\n\n4.1.2.3 Run The Model\n\nfit1 &lt;- lmer(outcome ~ warmth + physical_punishment + \n               group + HDI +\n               (1 + warmth || country),\n             data = df)\n\nsummary(fit1)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: outcome ~ warmth + physical_punishment + group + HDI + ((1 |  \n    country) + (0 + warmth | country))\n   Data: df\n\nREML criterion at convergence: 19350.3\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.4496 -0.6807  0.0016  0.6864  3.1792 \n\nRandom effects:\n Groups    Name        Variance  Std.Dev.\n country   (Intercept)  3.611568 1.90041 \n country.1 warmth       0.001876 0.04331 \n Residual              36.049124 6.00409 \nNumber of obs: 3000, groups:  country, 30\n\nFixed effects:\n                    Estimate Std. Error t value\n(Intercept)         49.88754    1.48203  33.662\nwarmth               0.96155    0.05875  16.367\nphysical_punishment -0.84556    0.07986 -10.588\ngroup                1.08471    0.22017   4.927\nHDI                  0.01044    0.02116   0.493\n\nCorrelation of Fixed Effects:\n            (Intr) warmth physc_ group \nwarmth      -0.126                     \nphyscl_pnsh -0.135 -0.025              \ngroup       -0.218 -0.010 -0.019       \nHDI         -0.925 -0.006  0.008 -0.001\n\n\n\n\n\n4.1.3 Julia\n\n4.1.3.1 Get The Data\n\nusing Tables, MixedModels, StatFiles, DataFrames, CategoricalArrays, DataFramesMeta\n\ndf = DataFrame(load(\"simulated_multilevel_data.dta\"))\n\n\n\n4.1.3.2 Graph\n\nusing StatsPlots\n\n@df df scatter(:outcome, :warmth, \n               title = \"Outcome by Parental Warmth\",\n               ylabel = \"outcome\",\n               xlabel = \"parental warmth\")\n\n\n\n\n\n\n\nFigure 4.3: Outcome by Parental Warmth (Julia)\n\n\n\n\n\n\n\n4.1.3.3 Change Country To Categorical\n\n@transform!(df, :country = categorical(:country))\n\n\n\n4.1.3.4 Run The Model\n\n\nm1 = fit(MixedModel, @formula(outcome ~ warmth + physical_punishment + \n               group + HDI +\n               (1 + warmth | country)), df)\n\nLinear mixed model fit by maximum likelihood\n outcome ~ 1 + warmth + physical_punishment + group + HDI + (1 + warmth | country)\n   logLik   -2 logLik     AIC       AICc        BIC    \n -9667.9392 19335.8783 19353.8783 19353.9385 19407.9357\n\nVariance components:\n            Column    Variance   Std.Dev.   Corr.\ncountry  (Intercept)   3.2369484 1.7991521\n         warmth        0.0001080 0.0103903 +1.00\nResidual              36.0187144 6.0015593\n Number of obs: 3000; levels of grouping factors: 30\n\n  Fixed-effects parameters:\n─────────────────────────────────────────────────────────────\n                          Coef.  Std. Error       z  Pr(&gt;|z|)\n─────────────────────────────────────────────────────────────\n(Intercept)          49.9018      1.43435     34.79    &lt;1e-99\nwarmth                0.961545    0.0582135   16.52    &lt;1e-60\nphysical_punishment  -0.845389    0.0798149  -10.59    &lt;1e-25\ngroup                 1.08524     0.220055     4.93    &lt;1e-06\nHDI                   0.0101984   0.0204401    0.50    0.6178\n─────────────────────────────────────────────────────────────\n\n\n\n\n\n\n\n\n\n\nFigure 4.1: Outcome by Parental Warmth (Stata)\nFigure 4.2: Outcome by Parental Warmth (R)\nFigure 4.3: Outcome by Parental Warmth (Julia)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cross Sectional Multilevel Models</span>"
    ]
  },
  {
    "objectID": "longitudinal-multilingual.html",
    "href": "longitudinal-multilingual.html",
    "title": "5  Longitudinal Multilevel Models",
    "section": "",
    "text": "5.1 The Data\nThe data employed in these examples are a longitudinal extension of the data described in Section 1.2.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Longitudinal Multilevel Models</span>"
    ]
  },
  {
    "objectID": "longitudinal-multilingual.html#the-data",
    "href": "longitudinal-multilingual.html#the-data",
    "title": "5  Longitudinal Multilevel Models",
    "section": "",
    "text": "Graphing Longitudinal Data\n\n\n\nIn the section on cross-sectional multilevel models, I employed scatterplots to graph the data. In longitudinal models, time is a variable of special interest. Often, in graphing longitudinal data–especially when graphing outcomes by time–it makes more sense to use linear fit plots, although a scatterplot could be employed as well.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Longitudinal Multilevel Models</span>"
    ]
  },
  {
    "objectID": "longitudinal-multilingual.html#the-equation",
    "href": "longitudinal-multilingual.html#the-equation",
    "title": "5  Longitudinal Multilevel Models",
    "section": "5.2 The Equation",
    "text": "5.2 The Equation\n\\[\\text{outcome}_{itj} = \\beta_0 + \\beta_1 \\text{parental warmth}_{itj} + \\beta_2 \\text{physical punishment}_{itj} + \\beta_3 \\text{time}_{itj} \\ +  \\tag{5.1}\\]\n\\[\\beta_4 \\text{group}_{itj} + \\beta_5 \\text{HDI}_{itj} +\\]\n\\[u_{0j} + u_{1j} \\times \\text{parental warmth}_{itj} \\ + \\]\n\\[v_{0i} + v_{1i} \\times \\text{time}_{itj} + e_{itj}\\] ## Run Models\n\nStataRJulia\n\n\n\n5.2.0.1 Get The Data\n\n\nuse simulated_multilevel_longitudinal_data.dta\n\n\n\n5.2.0.2 Graph\n\ntwoway lfit outcome t, ///\n  xtitle(\"time\") ytitle(\"outcome\") ///\n  title(\"Outcome by Time\") \n\nquietly graph export lfitlongitudinal.png, replace\n\n\n\n\n\n\n\nFigure 5.1: Outcome by Parental Warmth (Stata)\n\n\n\n\n\n5.2.0.3 Run The Model\n\n5.2.0.3.1 Main Effects Only\n\n\nmixed outcome t warmth physical_punishment group HDI || country: warmth\n\nPerforming EM optimization ...\n\nPerforming gradient-based optimization: \nIteration 0:  Log likelihood =  -28795.37  \nIteration 1:  Log likelihood = -28795.232  \nIteration 2:  Log likelihood = -28795.232  \n\nComputing standard errors ...\n\nMixed-effects ML regression                         Number of obs    =   9,000\nGroup variable: country                             Number of groups =      30\n                                                    Obs per group:\n                                                                 min =     300\n                                                                 avg =   300.0\n                                                                 max =     300\n                                                    Wald chi2(5)     = 1366.93\nLog likelihood = -28795.232                         Prob &gt; chi2      =  0.0000\n\n-------------------------------------------------------------------------------------\n            outcome | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n--------------------+----------------------------------------------------------------\n                  t |   .9882371   .0761439    12.98   0.000     .8389979    1.137476\n             warmth |   .9427117   .0342282    27.54   0.000     .8756256    1.009798\nphysical_punishment |  -.9020727   .0452759   -19.92   0.000    -.9908119   -.8133336\n              group |   .9861238   .1249047     7.90   0.000     .7413151    1.230933\n                HDI |   .0073726    .020661     0.36   0.721    -.0331222    .0478674\n              _cons |   49.45537   1.414072    34.97   0.000     46.68384     52.2269\n-------------------------------------------------------------------------------------\n\n------------------------------------------------------------------------------\n  Random-effects parameters  |   Estimate   Std. err.     [95% conf. interval]\n-----------------------------+------------------------------------------------\ncountry: Independent         |\n                 var(warmth) |   .0024684   .0082517      3.52e-06     1.72956\n                  var(_cons) |   3.663663   .9914845      2.155548     6.22692\n-----------------------------+------------------------------------------------\n               var(Residual) |   34.78483   .5200702       33.7803    35.81923\n------------------------------------------------------------------------------\nLR test vs. linear model: chi2(2) = 805.75                Prob &gt; chi2 = 0.0000\n\nNote: LR test is conservative and provided only for reference.\n\n\n\n\n5.2.0.3.2 Interactions With Time\n\n\nmixed outcome c.t##(c.warmth c.physical_punishment i.group c.HDI) || country: warmth\n\nPerforming EM optimization ...\n\nPerforming gradient-based optimization: \nIteration 0:  Log likelihood =  -28794.99  \nIteration 1:  Log likelihood = -28794.855  \nIteration 2:  Log likelihood = -28794.855  \n\nComputing standard errors ...\n\nMixed-effects ML regression                         Number of obs    =   9,000\nGroup variable: country                             Number of groups =      30\n                                                    Obs per group:\n                                                                 min =     300\n                                                                 avg =   300.0\n                                                                 max =     300\n                                                    Wald chi2(9)     = 1365.73\nLog likelihood = -28794.855                         Prob &gt; chi2      =  0.0000\n\n-------------------------------------------------------------------------------------\n            outcome | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n--------------------+----------------------------------------------------------------\n                  t |   1.047448   .3619795     2.89   0.004     .3379816    1.756915\n             warmth |   .8869901   .0876058    10.12   0.000      .715286    1.058694\nphysical_punishment |   -.893285   .1194705    -7.48   0.000    -1.127443    -.659127\n            2.group |   .9648545   .3292217     2.93   0.003     .3195918    1.610117\n                HDI |   .0120622    .022474     0.54   0.591    -.0319861    .0561104\n                    |\n       c.t#c.warmth |   .0277903   .0402665     0.69   0.490    -.0511306    .1067112\n                    |\n                c.t#|\n                 c. |\nphysical_punishment |  -.0041479   .0553051    -0.08   0.940    -.1125439    .1042482\n                    |\n          group#c.t |\n                 2  |   .0105177   .1523009     0.07   0.945    -.2879865    .3090219\n                    |\n          c.t#c.HDI |   -.002342   .0044172    -0.53   0.596    -.0109996    .0063155\n                    |\n              _cons |   50.32233   1.572089    32.01   0.000      47.2411    53.40357\n-------------------------------------------------------------------------------------\n\n------------------------------------------------------------------------------\n  Random-effects parameters  |   Estimate   Std. err.     [95% conf. interval]\n-----------------------------+------------------------------------------------\ncountry: Independent         |\n                 var(warmth) |   .0025661   .0083259      4.44e-06    1.482773\n                  var(_cons) |    3.66269    .991533      2.154617    6.226305\n-----------------------------+------------------------------------------------\n               var(Residual) |   34.78158   .5200283      33.77713     35.8159\n------------------------------------------------------------------------------\nLR test vs. linear model: chi2(2) = 805.90                Prob &gt; chi2 = 0.0000\n\nNote: LR test is conservative and provided only for reference.\n\n\n\n\n\n\n\n5.2.0.4 Get The Data\n\nlibrary(haven)\n\ndfL &lt;- read_dta(\"simulated_multilevel_longitudinal_data.dta\")\n\n\n\n5.2.0.5 Graph\n\nlibrary(ggplot2)\n\nggplot(dfL,\n       aes(x = t,\n           y = outcome)) + \n  geom_smooth(method = \"lm\") +\n  labs(title = \"Outcome by Time\")\n\n\n\n\n\n\n\nFigure 5.2: Outcome by Parental Warmth (R)\n\n\n\n\n\n\n\n5.2.0.6 Run The Model\n\n5.2.0.6.1 Main Effects Only\n\nfit2A &lt;- lmer(outcome ~ t + warmth + physical_punishment + \n               group + HDI +\n               (1 | country/id),\n             data = dfL)\n\nsummary(fit2A)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: outcome ~ t + warmth + physical_punishment + group + HDI + (1 |  \n    country/id)\n   Data: dfL\n\nREML criterion at convergence: 57088.4\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.4471 -0.6226  0.0081  0.6153  3.1993 \n\nRandom effects:\n Groups     Name        Variance Std.Dev.\n id:country (Intercept)  8.864   2.977   \n country    (Intercept)  3.924   1.981   \n Residual               26.008   5.100   \nNumber of obs: 9000, groups:  id:country, 3000; country, 30\n\nFixed effects:\n                     Estimate Std. Error t value\n(Intercept)         49.494782   1.471780  33.629\nt                    0.987964   0.065840  15.005\nwarmth               0.946259   0.038200  24.771\nphysical_punishment -0.926880   0.049970 -18.549\ngroup                0.985786   0.153550   6.420\nHDI                  0.007543   0.021437   0.352\n\nCorrelation of Fixed Effects:\n            (Intr) t      warmth physc_ group \nt           -0.090                            \nwarmth      -0.085  0.008                     \nphyscl_pnsh -0.085  0.003 -0.019              \ngroup       -0.154  0.000 -0.013 -0.008       \nHDI         -0.943  0.000 -0.003  0.003  0.000\n\n\n\n\n5.2.0.6.2 Interactions With Time\n\nfit2B &lt;- lmer(outcome ~ t *(warmth + physical_punishment + \n               group + HDI) +\n               (1 | country/id),\n             data = dfL)\n\nsummary(fit2B)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: outcome ~ t * (warmth + physical_punishment + group + HDI) +  \n    (1 | country/id)\n   Data: dfL\n\nREML criterion at convergence: 57107.3\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.4431 -0.6248  0.0071  0.6183  3.1961 \n\nRandom effects:\n Groups     Name        Variance Std.Dev.\n id:country (Intercept)  8.868   2.978   \n country    (Intercept)  3.925   1.981   \n Residual               26.014   5.100   \nNumber of obs: 9000, groups:  id:country, 3000; country, 30\n\nFixed effects:\n                       Estimate Std. Error t value\n(Intercept)           49.453036   1.637740  30.196\nt                      1.008199   0.364915   2.763\nwarmth                 0.865659   0.080487  10.755\nphysical_punishment   -0.908148   0.110449  -8.222\ngroup                  0.966988   0.304936   3.171\nHDI                    0.012277   0.022761   0.539\nt:warmth               0.040170   0.035364   1.136\nt:physical_punishment -0.008932   0.049262  -0.181\nt:group                0.009180   0.131714   0.070\nt:HDI                 -0.002359   0.003820  -0.618\n\nCorrelation of Fixed Effects:\n            (Intr) t      warmth physc_ group  HDI    t:wrmt t:phy_ t:grop\nt           -0.446                                                        \nwarmth      -0.159  0.278                                                 \nphyscl_pnsh -0.169  0.302 -0.022                                          \ngroup       -0.274  0.459 -0.010 -0.014                                   \nHDI         -0.900  0.227 -0.008  0.009 -0.001                            \nt:warmth     0.141 -0.316 -0.880  0.017  0.010  0.007                     \nt:physcl_pn  0.150 -0.338  0.017 -0.892  0.010 -0.007 -0.015              \nt:group      0.237 -0.532  0.009  0.012 -0.864  0.001 -0.012 -0.008       \nt:HDI        0.302 -0.676  0.018 -0.020  0.002 -0.336 -0.018  0.016 -0.002\n\n\n\n\n\n\n\n5.2.0.7 Get The Data\n\nusing Tables, MixedModels, StatFiles, DataFrames, CategoricalArrays, DataFramesMeta\n\ndfL = DataFrame(load(\"simulated_multilevel_longitudinal_data.dta\"))\n\n\n\n5.2.0.8 Graph\nTo make our plot with a smoother in Julia, we set the markercolor and markerstrokecolor to be white, and the smooth option to :true.\n\nusing StatsPlots\n\n@df dfL scatter(:outcome, :t, \n               title = \"Outcome by Parental Warmth\",\n               ylabel = \"outcome\",\n               xlabel = \"time\",\n               markercolor = \"white\",\n               markerstrokecolor = \"white\",\n               smooth=:true)\n\n\n\n\n\n\n\nFigure 5.3: Outcome by Parental Warmth (Julia)\n\n\n\n\n\n\n\n5.2.0.9 Run The Model\n\n5.2.0.9.1 Change Country To Categorical\n\n@transform!(dfL, :country = categorical(:country))\n\n\n\n5.2.0.9.2 Main Effects Only\n\n\nm2A = fit(MixedModel, @formula(outcome ~ t + warmth + \n                                 physical_punishment + \n                                 group + HDI +\n                                 (1 + warmth | country) +\n                                 (1 | id)), dfL)\n\nLinear mixed model fit by maximum likelihood\n outcome ~ 1 + t + warmth + physical_punishment + group + HDI + (1 + warmth | country) + (1 | id)\n    logLik   -2 logLik      AIC         AICc        BIC     \n -28533.9236  57067.8472  57089.8472  57089.8765  57168.0019\n\nVariance components:\n            Column    Variance Std.Dev.   Corr.\nid       (Intercept)   8.851224 2.975101\ncountry  (Intercept)   3.451345 1.857780\n         warmth        0.000227 0.015065 +1.00\nResidual              26.001212 5.099138\n Number of obs: 9000; levels of grouping factors: 3000, 30\n\n  Fixed-effects parameters:\n──────────────────────────────────────────────────────────────\n                           Coef.  Std. Error       z  Pr(&gt;|z|)\n──────────────────────────────────────────────────────────────\n(Intercept)          49.5105       1.41854     34.90    &lt;1e-99\nt                     0.98814      0.0658319   15.01    &lt;1e-50\nwarmth                0.946252     0.0382851   24.72    &lt;1e-99\nphysical_punishment  -0.926673     0.0499547  -18.55    &lt;1e-76\ngroup                 0.98708      0.153484     6.43    &lt;1e-09\nHDI                   0.00725703   0.0206549    0.35    0.7253\n──────────────────────────────────────────────────────────────\n\n\n\n\n5.2.0.9.3 Interactions With Time\n\n\nm2B = fit(MixedModel, @formula(outcome ~ t * (warmth + \n                                 physical_punishment + \n                                 group + HDI) +\n                                 (1 + warmth | country) +\n                                 (1 | id)), dfL)\n\nLinear mixed model fit by maximum likelihood\n outcome ~ 1 + t + warmth + physical_punishment + group + HDI + t & warmth + t & physical_punishment + t & group + t & HDI + (1 + warmth | country) + (1 | id)\n    logLik   -2 logLik      AIC         AICc        BIC     \n -28533.0810  57066.1620  57096.1620  57096.2154  57202.7367\n\nVariance components:\n            Column    Variance   Std.Dev.   Corr.\nid       (Intercept)   8.8593774 2.9764706\ncountry  (Intercept)   3.4464818 1.8564703\n         warmth        0.0002394 0.0154717 +1.00\nResidual              25.9905210 5.0980899\n Number of obs: 9000; levels of grouping factors: 3000, 30\n\n  Fixed-effects parameters:\n─────────────────────────────────────────────────────────────────\n                               Coef.  Std. Error      z  Pr(&gt;|z|)\n─────────────────────────────────────────────────────────────────\n(Intercept)              49.4696      1.59007     31.11    &lt;1e-99\nt                         1.00761     0.36475      2.76    0.0057\nwarmth                    0.865294    0.0804999   10.75    &lt;1e-26\nphysical_punishment      -0.907816    0.110399    -8.22    &lt;1e-15\ngroup                     0.96908     0.304797     3.18    0.0015\nHDI                       0.0119739   0.0220306    0.54    0.5868\nt & warmth                0.0403499   0.0353477    1.14    0.2537\nt & physical_punishment  -0.00900605  0.0492392   -0.18    0.8549\nt & group                 0.00879803  0.131655     0.07    0.9467\nt & HDI                  -0.00234513  0.00381848  -0.61    0.5391\n─────────────────────────────────────────────────────────────────\n\n\n\n\n\n\n\n\n\n\nFigure 5.1: Outcome by Parental Warmth (Stata)\nFigure 5.2: Outcome by Parental Warmth (R)\nFigure 5.3: Outcome by Parental Warmth (Julia)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Longitudinal Multilevel Models</span>"
    ]
  }
]