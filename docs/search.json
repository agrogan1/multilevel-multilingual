[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Multilevel Multilingual",
    "section": "",
    "text": "1 Multilevel Multilingual",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Multilevel Multilingual</span>"
    ]
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Multilevel Multilingual",
    "section": "1.1 Introduction",
    "text": "1.1 Introduction\nBelow, I describe the use of Stata (StataCorp, 2021), R (Bates et al., 2015; R Core Team, 2023), and Julia (Bates, 2024; Bezanson et al., 2017) to estimate multilevel models and to visualize data.\nAll of these software packages can estimate multilevel models and can visualize relationships in the data. However, there are substantial differences between the different packages: Stata is proprietary for cost software, which is very well documented and very intuitive. While it costs money to purchase Stata, the price is often very reasonable for academic and educational use. R is free open source software which is less intuitive, but there are many excellent resources for learning R. There is often a cost associated with purchasing books and other materials for learning R, which sometimes feels like it offsets the fact that R is free. Julia is newer open source software, and ostensibly much faster than either Stata or R, which may be an important advantage when running multilevel models with very large data sets. At this point in time, both Stata and R feel much more stable than Julia which is still evolving software.\nWhile any of these software packages can be used for learning and estimating multilevel models, I will offer my own opinion–based upon 15 years of teaching multilevel models at the doctoral level–that Stata offers the quickest pathway for learning the basic and advanced uses of multilevel models. I also believe the intuitive nature of Stata syntax contributes to accurate and replicable work in this area.\n\n\n\nTable 1.1: Software for Multilevel Modeling\n\n\n\n\n\n\n\n\n\n\nSoftware\nCost\nEase of Use\n\n\n\n\nStata\nsome cost\nlearning curve, but very intuitive for both multilevel modeling and graphing.\n\n\nR\nfree\nlearning curve: intuitive for multilevel modeling; but steeper learning curve for graphing (ggplot).\n\n\nJulia\nfree\nsteep learning curve in general: steep learning curve for multilevel modeling; and very steep learning curve for graphing. Graphics libraries are very much under development and in flux.\n\n\n\n\n\n\n\n\n\n\n\n\nResults Will Vary Somewhat\n\n\n\nEstimating multilevel models is a complex endeavor. The software details of how this is accomplished are beyond the purview of this book. Suffice it to say that across different software packages there will be differences in estimation routines, resulting in some numerical differences in the results provided by different software packages. Substantively speaking, however, results should agree across software.\n\n\n\n\n\n\n\n\nMulti-Line Commands\n\n\n\nSometimes I have written commands out over multiple lines. I have done this for especially long commands, but have also sometimes done this simply for the sake of clarity. The different software packages have different approaches to multi-line commands.\n\nBy default, Stata ends a command at the end of a line. If you are going to write a multi-line command you should use the /// line continuation characters.\nR is the software that most naturally can be written using multiple lines, as R commands are usually clearly encased in parentheses (()) or continued with + signs.\nLike Stata, Julia expects commands to end at the end of a line. If you are going to write a mult-line command, all commands except for the last line should end in a character that clearly indicates continuation, like a + sign. An alternative is to encase the entire Julia command in an outer set of parentheses (()).\n\n\n\n\n\n\n\n\n\nRunning Statistical Packages in Quarto\n\n\n\nI used Quarto (https://quarto.org/) to create this Appendix. Quarto is a programming and publishing environment that can run multiple programming languages, including Stata, R and Julia, and that can write to multiple output formats including HTML, PDF, and MS Word. To run Stata, I used the Statamarkdown library in R to connect Stata to Quarto. Quarto has a built in connection to R, and runs R without issue. To run Julia, I used the JuliaCall library in R to connect Quarto to Julia.\nOf course, each of these programs can be run by itself, if you have them installed on your computer.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Multilevel Multilingual</span>"
    ]
  },
  {
    "objectID": "index.html#sec-data",
    "href": "index.html#sec-data",
    "title": "Multilevel Multilingual",
    "section": "1.2 The Data",
    "text": "1.2 The Data\nThe examples use the simulated_multilevel_data.dta file from Multilevel Thinking. Here is a direct link to download the data.\n\n\n\n\nTable 1.2: Sample of Simulated Multilevel Data\n\n\n\n\nTable continues below\n\n\n\n\n\n\n\n\n\n\n\ncountry\nHDI\nfamily\nid\nidentity\nintervention\nphysical_punishment\n\n\n\n\n1\n69\n1\n1.1\n1\n0\n3\n\n\n1\n69\n2\n1.2\n1\n1\n2\n\n\n1\n69\n3\n1.3\n0\n1\n3\n\n\n1\n69\n4\n1.4\n1\n0\n0\n\n\n1\n69\n5\n1.5\n1\n0\n4\n\n\n1\n69\n6\n1.6\n0\n1\n5\n\n\n\n\n\n\n\n\n\n\nwarmth\noutcome\n\n\n\n\n3\n57.47\n\n\n1\n50.1\n\n\n2\n52.92\n\n\n5\n60.17\n\n\n4\n55.05\n\n\n3\n49.81",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Multilevel Multilingual</span>"
    ]
  },
  {
    "objectID": "index.html#sec-syntax",
    "href": "index.html#sec-syntax",
    "title": "Multilevel Multilingual",
    "section": "1.3 An Introduction To Equations and Syntax",
    "text": "1.3 An Introduction To Equations and Syntax\nTo explain statistical syntax for each software, I consider the general case of a multilevel model with dependent variable y, independent variables x and z, clustering variable group, and a random slope for x. i is the index for the person, while j is the index for the group.\n\\[y = \\beta_0 + \\beta_1 x_{ij} + \\beta_2 z_{ij} + u_{0j} + u_{1j} \\times x_{ij} + e_{ij} \\tag{1.1}\\]\n\nStataRJulia\n\n\nIn Stata mixed, the syntax for a multilevel model of the form described in Equation 1.1 is:\n\nmixed y x || group: x\n\n\n\nIn R lme4, the general syntax for a multilevel model of the form described in Equation 1.1 is:\n\nlibrary(lme4)\n\nlmer(y ~ x + z + (1 + x || group), data = ...)\n\n\n\nIn Julia MixedModels, the general syntax for a multilevel model of the form described in Equation 1.1 is:\n\nusing MixedModels\n\nfit(MixedModel, @formula(y ~ x + z + (1 + x | group)), data)\n\n\n\n\n\n\n\n\nBates, D. (2024). MixedModels.jl Documentation. https://juliastats.org/MixedModels.jl/stable/\n\n\nBates, D., Mächler, M., Bolker, B., & Walker, S. (2015). Fitting linear mixed-effects models using lme4. Journal of Statistical Software, 67(1), 1–48. https://doi.org/10.18637/jss.v067.i01\n\n\nBezanson, J., Edelman, A., Karpinski, S., & Shah, V. B. (2017). Julia: A fresh approach to numerical computing. SIAM Review, 59(1), 65–98. https://doi.org/10.1137/141000671\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nSchanen, J. (2021). Math person (Strogatz Prize entry). National Museum of Mathematics.\n\n\nStataCorp. (2021). Stata 17 multilevel mixed effects reference manual. Stata Press.\n\n\nThoreau, H. D. (1975). The commercial spirit of modern times [1837]. In J. J. Moldenhauer, E. Moser, & A. C. Kern (Eds.), Early essays and miscellanies. Princeton University Press.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Multilevel Multilingual</span>"
    ]
  },
  {
    "objectID": "descriptives-multilingual.html",
    "href": "descriptives-multilingual.html",
    "title": "2  Descriptive Statistics",
    "section": "",
    "text": "2.1 Descriptive Statistics",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "descriptives-multilingual.html#descriptive-statistics",
    "href": "descriptives-multilingual.html#descriptive-statistics",
    "title": "2  Descriptive Statistics",
    "section": "",
    "text": "StataRJulia\n\n\n\n\nuse simulated_multilevel_data.dta // use data\n\nWe use summarize for continuous variables, and tabulate for categorical variables.\n\nsummarize outcome warmth physical_punishment HDI\n\ntabulate identity\n\ntabulate intervention\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n     outcome |      3,000    52.43327    6.530996   29.60798   74.83553\n      warmth |      3,000    3.521667    1.888399          0          7\nphysical_p~t |      3,000    2.478667    1.360942          0          5\n         HDI |      3,000    64.76667    17.24562         33         87\n\n\nhypothetica |\n l identity |\n      group |\n   variable |      Freq.     Percent        Cum.\n------------+-----------------------------------\n          1 |      1,507       50.23       50.23\n          2 |      1,493       49.77      100.00\n------------+-----------------------------------\n      Total |      3,000      100.00\n\n\n   recieved |\ninterventio |\n          n |      Freq.     Percent        Cum.\n------------+-----------------------------------\n          0 |      1,547       51.57       51.57\n          1 |      1,453       48.43      100.00\n------------+-----------------------------------\n      Total |      3,000      100.00\n\n\n\n\n\nlibrary(haven) # read data in Stata format\n\ndf &lt;- read_dta(\"simulated_multilevel_data.dta\")\n\nR’s descriptive statistics functions rely heavily on whether a variable is a numeric variable, or a factor variable. Below, I convert two variables to factors (factor) before using summary1 to generate descriptive statistics.\n\ndf$country &lt;- factor(df$country)\n\ndf$identity &lt;- factor(df$identity)\n\ndf$intervention &lt;- factor(df$intervention)\n\nsummary(df)\n\n    country          HDI            family            id            identity\n 1      : 100   Min.   :33.00   Min.   :  1.00   Length:3000        1:1507  \n 2      : 100   1st Qu.:53.00   1st Qu.: 25.75   Class :character   2:1493  \n 3      : 100   Median :70.00   Median : 50.50   Mode  :character           \n 4      : 100   Mean   :64.77   Mean   : 50.50                              \n 5      : 100   3rd Qu.:81.00   3rd Qu.: 75.25                              \n 6      : 100   Max.   :87.00   Max.   :100.00                              \n (Other):2400                                                               \n intervention physical_punishment     warmth         outcome     \n 0:1547       Min.   :0.000       Min.   :0.000   Min.   :29.61  \n 1:1453       1st Qu.:2.000       1st Qu.:2.000   1st Qu.:48.02  \n              Median :2.000       Median :4.000   Median :52.45  \n              Mean   :2.479       Mean   :3.522   Mean   :52.43  \n              3rd Qu.:3.000       3rd Qu.:5.000   3rd Qu.:56.86  \n              Max.   :5.000       Max.   :7.000   Max.   :74.84  \n                                                                 \n\n\n\n\n\nusing Tables, MixedModels, MixedModelsExtras, StatFiles, DataFrames, CategoricalArrays, DataFramesMeta\n\ndf = DataFrame(load(\"simulated_multilevel_data.dta\"))\n\nSimilarly to R, Julia relies on the idea of variable type. I use transform to convert the appropriate variables to categorical variables.\n\n@transform!(df, :country = categorical(:country))\n\n@transform!(df, :identity = categorical(:identity))\n\n@transform!(df, :intervention = categorical(:intervention))\n\n\n\ndescribe(df) # descriptive statistics\n\n9×7 DataFrame\n Row │ variable             mean     min     median  max      nmissing  eltype ⋯\n     │ Symbol               Union…   Any     Union…  Any      Int64     Union  ⋯\n─────┼──────────────────────────────────────────────────────────────────────────\n   1 │ country                       1.0             30.0            0  Union{ ⋯\n   2 │ HDI                  64.7667  33.0    70.0    87.0            0  Union{\n   3 │ family               50.5     1.0     50.5    100.0           0  Union{\n   4 │ id                            1.1             9.99            0  Union{\n   5 │ identity                      1.0             2.0             0  Union{ ⋯\n   6 │ intervention                  0.0             1.0             0  Union{\n   7 │ physical_punishment  2.47867  0.0     2.0     5.0             0  Union{\n   8 │ warmth               3.52167  0.0     4.0     7.0             0  Union{\n   9 │ outcome              52.4333  29.608  52.449  74.8355         0  Union{ ⋯\n                                                                1 column omitted",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "descriptives-multilingual.html#interpretation",
    "href": "descriptives-multilingual.html#interpretation",
    "title": "2  Descriptive Statistics",
    "section": "2.2 Interpretation",
    "text": "2.2 Interpretation\nExamining descriptive statistics is an important first step in any analysis. It is important to examine your descriptive statistics first, before skipping ahead to more sophisticated analyses, such as multilevel models.\nIn examining the descriptive statistics for this data, we get a sense of the data.\n\noutcome has a mean of approximately 52 and ranges from approximately 30 to 75.\nwarmth and physical punishment are both variables that represent the number of times that parents use each of these forms of discipline in a week. The average of the former is about 3.5, while the average of the latter is about 2.5.\nHDI, the Human Development Index has an average of about 65, and a wide range.\nidentity is a categorical variable for a hypothetical identity group, and has values of 1 and 2.\nintervention is also a categorical variable, and has values of 0 and 1.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "descriptives-multilingual.html#footnotes",
    "href": "descriptives-multilingual.html#footnotes",
    "title": "2  Descriptive Statistics",
    "section": "",
    "text": "skimr is an excellent new alternative library for generating descriptive statistics in R.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "unconditional-multilingual.html",
    "href": "unconditional-multilingual.html",
    "title": "3  Unconditional Model",
    "section": "",
    "text": "3.1 The Equation\n\\[\\text{outcome}_{ij}= \\beta_0 + u_{0j} + e_{ij} \\tag{3.1}\\]\nThe Intraclass Correlation Coefficient (ICC) is given by:\n\\[\\text{ICC} = \\frac{var(u_{0j})}{var(u_{0j}) + var(e_{ij})} \\tag{3.2}\\]\nIn a two level multilevel model, the ICC provides a measure of the amount of variation attributable to Level 2.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Unconditional Model</span>"
    ]
  },
  {
    "objectID": "unconditional-multilingual.html#run-models",
    "href": "unconditional-multilingual.html#run-models",
    "title": "3  Unconditional Model",
    "section": "3.2 Run Models",
    "text": "3.2 Run Models\n\nStataRJulia\n\n\n\n\nuse simulated_multilevel_data.dta // use data\n\n\n\nmixed outcome || country: // unconditional model\n  \n\nPerforming EM optimization ...\n\nPerforming gradient-based optimization: \nIteration 0:  Log likelihood = -9802.8371  \nIteration 1:  Log likelihood = -9802.8371  \n\nComputing standard errors ...\n\nMixed-effects ML regression                           Number of obs    = 3,000\nGroup variable: country                               Number of groups =    30\n                                                      Obs per group:\n                                                                   min =   100\n                                                                   avg = 100.0\n                                                                   max =   100\n                                                      Wald chi2(0)     =     .\nLog likelihood = -9802.8371                           Prob &gt; chi2      =     .\n\n------------------------------------------------------------------------------\n     outcome | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n       _cons |   52.43327   .3451217   151.93   0.000     51.75685     53.1097\n------------------------------------------------------------------------------\n\n------------------------------------------------------------------------------\n  Random-effects parameters  |   Estimate   Std. err.     [95% conf. interval]\n-----------------------------+------------------------------------------------\ncountry: Identity            |\n                  var(_cons) |   3.178658   .9226737      1.799552    5.614658\n-----------------------------+------------------------------------------------\n               var(Residual) |   39.46106   1.024013      37.50421       41.52\n------------------------------------------------------------------------------\nLR test vs. linear model: chibar2(01) = 166.31        Prob &gt;= chibar2 = 0.0000\n\n\n\n  \nestat icc // ICC\n\nIntraclass correlation\n\n------------------------------------------------------------------------------\n                       Level |        ICC   Std. err.     [95% conf. interval]\n-----------------------------+------------------------------------------------\n                     country |   .0745469   .0201254      .0434963    .1248696\n------------------------------------------------------------------------------\n\n\n\n\n\nlibrary(haven)\n\ndf &lt;- read_dta(\"simulated_multilevel_data.dta\")\n\n\nlibrary(lme4) # estimate multilevel models\n\nfit0 &lt;- lmer(outcome ~ (1 | country),\n             data = df) # unconditional model\n\nsummary(fit0)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: outcome ~ (1 | country)\n   Data: df\n\nREML criterion at convergence: 19605.9\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.3844 -0.6655 -0.0086  0.6725  3.6626 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n country  (Intercept)  3.302   1.817   \n Residual             39.461   6.282   \nNumber of obs: 3000, groups:  country, 30\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)   52.433      0.351   149.4\n\n\n\nlibrary(performance)\n\nperformance::icc(fit0) # ICC\n\n# Intraclass Correlation Coefficient\n\n    Adjusted ICC: 0.077\n  Unadjusted ICC: 0.077\n\n\n\n\n\nusing Tables, MixedModels, MixedModelsExtras, \nStatFiles, DataFrames, CategoricalArrays, DataFramesMeta\n\ndf = DataFrame(load(\"simulated_multilevel_data.dta\"))\n\n\n@transform!(df, :country = categorical(:country))\n\n\n\nm0 = fit(MixedModel, \n         @formula(outcome ~ (1 | country)), df) # unconditional model\n\nLinear mixed model fit by maximum likelihood\n outcome ~ 1 + (1 | country)\n   logLik   -2 logLik     AIC       AICc        BIC    \n -9802.8371 19605.6742 19611.6742 19611.6822 19629.6933\n\nVariance components:\n            Column   Variance Std.Dev.\ncountry  (Intercept)   3.17863 1.78287\nResidual              39.46106 6.28180\n Number of obs: 3000; levels of grouping factors: 30\n\n  Fixed-effects parameters:\n──────────────────────────────────────────────────\n               Coef.  Std. Error       z  Pr(&gt;|z|)\n──────────────────────────────────────────────────\n(Intercept)  52.4333    0.345121  151.93    &lt;1e-99\n──────────────────────────────────────────────────\n\n\n\n\nicc(m0) # ICC\n\n0.07454637475695493",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Unconditional Model</span>"
    ]
  },
  {
    "objectID": "unconditional-multilingual.html#interpretation",
    "href": "unconditional-multilingual.html#interpretation",
    "title": "3  Unconditional Model",
    "section": "3.3 Interpretation",
    "text": "3.3 Interpretation\nIn each case, the software finds that nearly 8% of the variation in the outcome is explainable by the clustering of the observations in each country.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Unconditional Model</span>"
    ]
  },
  {
    "objectID": "cross-sectional-multilingual.html",
    "href": "cross-sectional-multilingual.html",
    "title": "4  Cross Sectional Multilevel Models",
    "section": "",
    "text": "4.1 The Equation\nRecall the general model of Equation 1.1, and the syntax outlined in Section 1.3. Below in Equation 4.1, we consider a more substantive example.\n\\[\\text{outcome}_{ij}= \\beta_0 + \\beta_1 \\text{warmth}_{ij} + \\tag{4.1}\\]\n\\[\\beta_2 \\text{physical punishment}_{ij} +\\]\n\\[\\beta_3 \\text{identity}_{ij} + \\beta_4 \\text{intervention}_{ij} + \\beta_5 \\text{HDI}_{ij} +\\]\n\\[u_{0j} + u_{1j} \\times \\text{warmth}_{ij} + e_{ij}\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cross Sectional Multilevel Models</span>"
    ]
  },
  {
    "objectID": "cross-sectional-multilingual.html#correlated-and-uncorrelated-random-effects",
    "href": "cross-sectional-multilingual.html#correlated-and-uncorrelated-random-effects",
    "title": "4  Cross Sectional Multilevel Models",
    "section": "4.2 Correlated and Uncorrelated Random Effects",
    "text": "4.2 Correlated and Uncorrelated Random Effects\nConsider the covariance matrix of random effects (e.g. \\(u_{0j}\\) and \\(u_{1j}\\)). In Equation 4.2 the covariances of the random effects are constrained to be zero.\n\\[\\begin{bmatrix}\nvar(u_{0j}) & 0 \\\\\n0 & var(u_{1j})\n\\end{bmatrix} \\tag{4.2}\\]\nAs discussed in the Chapter on multilevel models with cross-sectional data, however, one can consider a multilevel model in which the random effects are correlated, as is the case in Equation 4.3.\n\\[\\begin{bmatrix}\nvar(u_{0j}) & cov(u_{0j}, u_{1j}) \\\\\ncov(u_{0j}, u_{1j}) & var(u_{1j})\n\\end{bmatrix} \\tag{4.3}\\]\nProcedures for estimating models with uncorrelated and correlated random effects are detailed below (Bates et al., 2015; Bates, 2024; StataCorp, 2021).\n\n\n\nTable 4.1: Correlated and Uncorrelated Random Effects\n\n\n\n\n\n\n\n\n\n\nSoftware\nUncorrelated Random Effects\nCorrelated Random Effects\n\n\n\n\nStata\ndefault\nadd option: , cov(uns)\n\n\nR\nseparate random effects from grouping variable with ||\nseparate random effects from grouping variable with |\n\n\nJulia\nseparate terms for each random effect e.g. (1 | group) + (0 + x | group)\nseparate random effects from grouping variable with |.\n\n\n\n\n\n\nAll models in the examples below are run with uncorrelated random effects, but could just as easily be run with correlated random effects.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cross Sectional Multilevel Models</span>"
    ]
  },
  {
    "objectID": "cross-sectional-multilingual.html#run-models",
    "href": "cross-sectional-multilingual.html#run-models",
    "title": "4  Cross Sectional Multilevel Models",
    "section": "4.3 Run Models",
    "text": "4.3 Run Models\n\nStataRJulia\n\n\n\n4.3.0.1 Get The Data\n\n\nuse simulated_multilevel_data.dta\n\n\n\n4.3.0.2 Run The Model\n\nmixed outcome warmth physical_punishment i.identity i.intervention HDI || country: warmth\n\nPerforming EM optimization ...\n\nPerforming gradient-based optimization: \nIteration 0:  Log likelihood = -9626.6279  \nIteration 1:  Log likelihood =  -9626.607  \nIteration 2:  Log likelihood =  -9626.607  \n\nComputing standard errors ...\n\nMixed-effects ML regression                          Number of obs    =  3,000\nGroup variable: country                              Number of groups =     30\n                                                     Obs per group:\n                                                                  min =    100\n                                                                  avg =  100.0\n                                                                  max =    100\n                                                     Wald chi2(5)     = 334.14\nLog likelihood =  -9626.607                          Prob &gt; chi2      = 0.0000\n\n-------------------------------------------------------------------------------------\n            outcome | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n--------------------+----------------------------------------------------------------\n             warmth |   .8345368   .0637213    13.10   0.000     .7096453    .9594282\nphysical_punishment |  -.9916657   .0797906   -12.43   0.000    -1.148052   -.8352791\n         2.identity |  -.3004767   .2170295    -1.38   0.166    -.7258466    .1248933\n     1.intervention |   .6396427   .2174519     2.94   0.003     .2134448    1.065841\n                HDI |   -.003228   .0199257    -0.16   0.871    -.0422817    .0358256\n              _cons |   51.99991   1.371257    37.92   0.000      49.3123    54.68753\n-------------------------------------------------------------------------------------\n\n------------------------------------------------------------------------------\n  Random-effects parameters  |   Estimate   Std. err.     [95% conf. interval]\n-----------------------------+------------------------------------------------\ncountry: Independent         |\n                 var(warmth) |   .0227504   .0257784      .0024689    .2096436\n                  var(_cons) |   2.963975   .9737647      1.556777    5.643163\n-----------------------------+------------------------------------------------\n               var(Residual) |   34.97499   .9097109      33.23668    36.80422\n------------------------------------------------------------------------------\nLR test vs. linear model: chi2(2) = 205.74                Prob &gt; chi2 = 0.0000\n\nNote: LR test is conservative and provided only for reference.\n\n\n\n\n\n\n4.3.0.3 Get The Data\n\nlibrary(haven)\n\ndf &lt;- read_dta(\"simulated_multilevel_data.dta\")\n\n\n\n4.3.0.4 Run The Model\n\n\n\n\n\n\nCaution\n\n\n\n\n\nlme4 does not directly provide p values in results, because of some disagreement over exactly how these p values should be calculated. Therefore, in this Appendix, I also call library lmerTest to provide p values for lme4 results.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nR prefers to use scientific notation when possible. I find that the use of scientific notation can be confusing in reading results. I turn off scientific notation by setting a penalty for its use: options(scipen = 999).\n\n\n\nlibrary(lme4) \n\nlibrary(lmerTest)\n\noptions(scipen = 999) \n\nfit1 &lt;- lmer(outcome ~ warmth + physical_punishment + \n               identity + intervention + HDI +\n               (1 + warmth || country),\n             data = df)\n\nsummary(fit1)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: outcome ~ warmth + physical_punishment + identity + intervention +  \n    HDI + (1 + warmth || country)\n   Data: df\n\nREML criterion at convergence: 19268.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.9774 -0.6563  0.0187  0.6645  3.6730 \n\nRandom effects:\n Groups    Name        Variance Std.Dev.\n country   (Intercept)  3.19056 1.786   \n country.1 warmth       0.02465 0.157   \n Residual              35.01782 5.918   \nNumber of obs: 3000, groups:  country, 30\n\nFixed effects:\n                       Estimate  Std. Error          df t value\n(Intercept)           52.311714    1.446735   33.113738  36.158\nwarmth                 0.834562    0.064252   41.896966  12.989\nphysical_punishment   -0.991892    0.079845 2968.010901 -12.423\nidentity              -0.300350    0.217179 2970.106304  -1.383\nintervention           0.639059    0.217603 2971.185215   2.937\nHDI                   -0.003395    0.020596   27.598517  -0.165\n                                Pr(&gt;|t|)    \n(Intercept)         &lt; 0.0000000000000002 ***\nwarmth              0.000000000000000277 ***\nphysical_punishment &lt; 0.0000000000000002 ***\nidentity                         0.16678    \nintervention                     0.00334 ** \nHDI                              0.87027    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) warmth physc_ idntty intrvn\nwarmth      -0.119                            \nphyscl_pnsh -0.145 -0.003                     \nidentity    -0.220 -0.012 -0.003              \ninterventin -0.077  0.034  0.022 -0.018       \nHDI         -0.922 -0.006  0.009 -0.001  0.000\n\n\n\n\n\n\n4.3.0.5 Get The Data\n\nusing Tables, MixedModels, StatFiles, DataFrames, CategoricalArrays, DataFramesMeta\n\ndf = DataFrame(load(\"simulated_multilevel_data.dta\"))\n\n\n\n4.3.0.6 Change Country To Categorical\n\n@transform!(df, :country = categorical(:country))\n\n\n\n4.3.0.7 Run The Model\n\n\nm1 = fit(MixedModel, @formula(outcome ~ warmth + physical_punishment + \n               identity + intervention + HDI +\n               (1 | country) +\n               (0 + warmth | country)), df)\n\nLinear mixed model fit by maximum likelihood\n outcome ~ 1 + warmth + physical_punishment + identity + intervention + HDI + (1 | country) + (0 + warmth | country)\n   logLik   -2 logLik     AIC       AICc        BIC    \n -9626.6070 19253.2140 19271.2140 19271.2742 19325.2713\n\nVariance components:\n            Column    Variance Std.Dev.   Corr.\ncountry  (Intercept)   2.963849 1.721583\n         warmth        0.022756 0.150852   .  \nResidual              34.974984 5.913965\n Number of obs: 3000; levels of grouping factors: 30\n\n  Fixed-effects parameters:\n─────────────────────────────────────────────────────────────\n                          Coef.  Std. Error       z  Pr(&gt;|z|)\n─────────────────────────────────────────────────────────────\n(Intercept)          52.3004      1.40406     37.25    &lt;1e-99\nwarmth                0.834537    0.0637228   13.10    &lt;1e-38\nphysical_punishment  -0.991665    0.0797906  -12.43    &lt;1e-34\nidentity             -0.300475    0.217029    -1.38    0.1662\nintervention          0.639641    0.217452     2.94    0.0033\nHDI                  -0.0032286   0.0199255   -0.16    0.8713\n─────────────────────────────────────────────────────────────",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cross Sectional Multilevel Models</span>"
    ]
  },
  {
    "objectID": "cross-sectional-multilingual.html#interpretation",
    "href": "cross-sectional-multilingual.html#interpretation",
    "title": "4  Cross Sectional Multilevel Models",
    "section": "4.4 Interpretation",
    "text": "4.4 Interpretation\nModels suggest that parental warmth is associated with increases in the beneficial outcome, while physical punishment is associated with decreases in the beneficial outcome. Membership in the group represented by identity is not associated with the outcome. The intervention is associated with increases in the outcome. The Human Development Index is not associated with the outcome.\n\n\n\n\nBates, D. (2024). MixedModels.jl Documentation. https://juliastats.org/MixedModels.jl/stable/\n\n\nBates, D., Mächler, M., Bolker, B., & Walker, S. (2015). Fitting linear mixed-effects models using lme4. Journal of Statistical Software, 67(1), 1–48. https://doi.org/10.18637/jss.v067.i01\n\n\nStataCorp. (2021). Stata 17 multilevel mixed effects reference manual. Stata Press.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cross Sectional Multilevel Models</span>"
    ]
  },
  {
    "objectID": "longitudinal-multilingual.html",
    "href": "longitudinal-multilingual.html",
    "title": "5  Longitudinal Multilevel Models",
    "section": "",
    "text": "5.1 The Data\nThe data employed in these examples are a longitudinal extension of the data described in Section 1.2.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Longitudinal Multilevel Models</span>"
    ]
  },
  {
    "objectID": "longitudinal-multilingual.html#the-equation",
    "href": "longitudinal-multilingual.html#the-equation",
    "title": "5  Longitudinal Multilevel Models",
    "section": "5.2 The Equation",
    "text": "5.2 The Equation\n\\[\\text{outcome}_{itj} = \\beta_0 + \\beta_1 \\text{parental warmth}_{itj} + \\beta_2 \\text{physical punishment}_{itj} + \\beta_3 \\text{time}_{itj} \\ +  \\tag{5.1}\\]\n\\[\\beta_4 \\text{identity}_{itj} + \\beta_5 \\text{intervention}_{itj} + \\beta_6 \\text{HDI}_{itj} +\\]\n\\[u_{0j} + u_{1j} \\times \\text{parental warmth}_{itj} \\ + \\]\n\\[v_{0i} + v_{1i} \\times \\text{time}_{itj} + e_{itj}\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Longitudinal Multilevel Models</span>"
    ]
  },
  {
    "objectID": "longitudinal-multilingual.html#growth-trajectories",
    "href": "longitudinal-multilingual.html#growth-trajectories",
    "title": "5  Longitudinal Multilevel Models",
    "section": "5.3 Growth Trajectories",
    "text": "5.3 Growth Trajectories\nRemember, following Section 6.4, that in longitudinal multilevel models, the variable for time assumes an important role as we are often thinking of a growth trajectory over time.\nAs discussed in Section 6.4, think about a model where identity is a (1/0) variable for membership in one of two groups:\n\\[\\text{outcome} = \\beta_0 + \\beta_t \\text{time} + \\beta_\\text{identity} \\text{identity} + \\beta_\\text{interaction} \\text{identity} \\times \\text{time} + u_{0i} + e_{it}\\]\nThen, each identity group has its own intercept and time trajectory:\n\n\n\nTable 5.1: Slope and Intercept for Each Group\n\n\n\n\n\n\n\n\n\n\nGroup\nIntercept\nSlope (Time Trajectory)\n\n\n\n\n0\n\\(\\beta_0\\)\n\\(\\beta_t\\)\n\n\n1\n\\(\\beta_0 + \\beta_\\text{identity}\\)\n\\(\\beta_t + \\beta_\\text{interaction}\\)\n\n\n\n\n\n\n\n\n\n\n\n\nMain Effects and Interactions\n\n\n\nThus, again following Section 6.4, in longitudinal multilevel models, main effects modify the intercept of the time trajectory, while interactions with time, modify the slope of the time trajectory. Below, we run models with main effects only, then models with main effects, and interactions with time.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Longitudinal Multilevel Models</span>"
    ]
  },
  {
    "objectID": "longitudinal-multilingual.html#run-models",
    "href": "longitudinal-multilingual.html#run-models",
    "title": "5  Longitudinal Multilevel Models",
    "section": "5.4 Run Models",
    "text": "5.4 Run Models\n\nStataRJulia\n\n\n\n5.4.0.1 Get The Data\n\n\nuse simulated_multilevel_longitudinal_data.dta\n\n\n\n5.4.0.2 Run The Model\n\n5.4.0.2.1 Main Effects Only\n\nmixed outcome t warmth physical_punishment i.identity i.intervention HDI || country: warmth\n\nPerforming EM optimization ...\n\nPerforming gradient-based optimization: \nIteration 0:  Log likelihood = -28739.506  \nIteration 1:  Log likelihood = -28739.506  \n\nComputing standard errors ...\n\nMixed-effects ML regression                         Number of obs    =   9,000\nGroup variable: country                             Number of groups =      30\n                                                    Obs per group:\n                                                                 min =     300\n                                                                 avg =   300.0\n                                                                 max =     300\n                                                    Wald chi2(6)     = 1119.81\nLog likelihood = -28739.506                         Prob &gt; chi2      =  0.0000\n\n-------------------------------------------------------------------------------------\n            outcome | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n--------------------+----------------------------------------------------------------\n                  t |   .9443446   .0756408    12.48   0.000     .7960914    1.092598\n             warmth |   .9123903   .0430042    21.22   0.000     .8281035     .996677\nphysical_punishment |  -.9881587   .0451732   -21.87   0.000    -1.076696   -.8996209\n         2.identity |  -.1241465   .1242225    -1.00   0.318     -.367618    .1193251\n     1.intervention |   .8575839   .1245179     6.89   0.000     .6135332    1.101635\n                HDI |  -.0025173   .0191696    -0.13   0.896    -.0400891    .0350544\n              _cons |   50.54528   1.304146    38.76   0.000      47.9892    53.10136\n-------------------------------------------------------------------------------------\n\n------------------------------------------------------------------------------\n  Random-effects parameters  |   Estimate   Std. err.     [95% conf. interval]\n-----------------------------+------------------------------------------------\ncountry: Independent         |\n                 var(warmth) |   .0229349   .0135353      .0072136    .0729194\n                  var(_cons) |     3.0009   .8550708      1.716768    5.245553\n-----------------------------+------------------------------------------------\n               var(Residual) |   34.31935   .5130963       33.3283    35.33988\n------------------------------------------------------------------------------\nLR test vs. linear model: chi2(2) = 767.22                Prob &gt; chi2 = 0.0000\n\nNote: LR test is conservative and provided only for reference.\n\n\n\n\n5.4.0.2.2 Interactions With Time\n\nmixed outcome c.t##(c.warmth c.physical_punishment i.identity i.intervention c.HDI) || country: warmth\n\nPerforming EM optimization ...\n\nPerforming gradient-based optimization: \nIteration 0:  Log likelihood = -28738.554  \nIteration 1:  Log likelihood = -28738.554  \n\nComputing standard errors ...\n\nMixed-effects ML regression                         Number of obs    =   9,000\nGroup variable: country                             Number of groups =      30\n                                                    Obs per group:\n                                                                 min =     300\n                                                                 avg =   300.0\n                                                                 max =     300\n                                                    Wald chi2(11)    = 1122.75\nLog likelihood = -28738.554                         Prob &gt; chi2      =  0.0000\n\n---------------------------------------------------------------------------------------\n              outcome | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n----------------------+----------------------------------------------------------------\n                    t |   .7537359   .3719996     2.03   0.043     .0246301    1.482842\n               warmth |   .8198365   .0911059     9.00   0.000     .6412723    .9984008\n  physical_punishment |  -1.000348   .1198049    -8.35   0.000    -1.235162   -.7655353\n           2.identity |  -.2340191   .3271243    -0.72   0.474     -.875171    .4071327\n       1.intervention |   .6597456   .3275877     2.01   0.044     .0176856    1.301806\n                  HDI |  -.0005531   .0210866    -0.03   0.979     -.041882    .0407757\n                      |\n         c.t#c.warmth |   .0463746   .0402459     1.15   0.249    -.0325059    .1252551\n                      |\n                  c.t#|\nc.physical_punishment |   .0061255   .0551491     0.11   0.912    -.1019647    .1142157\n                      |\n         identity#c.t |\n                   2  |   .0548965   .1513015     0.36   0.717     -.241649    .3514421\n                      |\n     intervention#c.t |\n                   1  |   .0990704    .151503     0.65   0.513      -.19787    .3960108\n                      |\n            c.t#c.HDI |  -.0009791   .0043888    -0.22   0.823    -.0095811    .0076229\n                      |\n                _cons |   50.92503   1.494157    34.08   0.000     47.99654    53.85352\n---------------------------------------------------------------------------------------\n\n------------------------------------------------------------------------------\n  Random-effects parameters  |   Estimate   Std. err.     [95% conf. interval]\n-----------------------------+------------------------------------------------\ncountry: Independent         |\n                 var(warmth) |   .0228292   .0135078      .0071588    .0728013\n                  var(_cons) |   3.001849   .8552796       1.71738    5.247001\n-----------------------------+------------------------------------------------\n               var(Residual) |   34.31227   .5129896      33.32141    35.33258\n------------------------------------------------------------------------------\nLR test vs. linear model: chi2(2) = 767.35                Prob &gt; chi2 = 0.0000\n\nNote: LR test is conservative and provided only for reference.\n\n\n\n\n\n\n\n5.4.0.3 Get The Data\n\nlibrary(haven)\n\ndfL &lt;- read_dta(\"simulated_multilevel_longitudinal_data.dta\")\n\n\n\n5.4.0.4 Run The Model\n\n\n\n\n\n\nCaution\n\n\n\n\n\nlme4 does not directly provide p values in results, because of some disagreement over exactly how these p values should be calculated. Therefore, in this Appendix, I also call library lmerTest to provide p values for lme4 results.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nR prefers to use scientific notation when possible. I find that the use of scientific notation can be confusing in reading results. I turn off scientific notation by setting a penalty for its use: options(scipen = 999).\n\n\n\n5.4.0.4.1 Main Effects Only\n\nlibrary(lme4) \n\nlibrary(lmerTest)\n\noptions(scipen = 999) \n\nfit2A &lt;- lmer(outcome ~ t + warmth + physical_punishment + \n               identity + intervention + HDI +\n               (1 | country/id),\n             data = dfL)\n\nsummary(fit2A)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: \noutcome ~ t + warmth + physical_punishment + identity + intervention +  \n    HDI + (1 | country/id)\n   Data: dfL\n\nREML criterion at convergence: 57022.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6850 -0.6094 -0.0035  0.6133  3.6792 \n\nRandom effects:\n Groups     Name        Variance Std.Dev.\n id:country (Intercept)  8.438   2.905   \n country    (Intercept)  3.675   1.917   \n Residual               26.036   5.103   \nNumber of obs: 9000, groups:  id:country, 3000; country, 30\n\nFixed effects:\n                        Estimate   Std. Error           df t value\n(Intercept)           50.5161891    1.4296454   31.1737942  35.335\nt                      0.9433806    0.0658755 5998.3764616  14.321\nwarmth                 0.9140307    0.0379336 4745.3496835  24.096\nphysical_punishment   -1.0087537    0.0497972 6483.6770989 -20.257\nidentity              -0.1319548    0.1517350 2968.7829265  -0.870\nintervention           0.8591494    0.1520510 2971.8112001   5.650\nHDI                    0.0007909    0.0207656   28.0001836   0.038\n                                Pr(&gt;|t|)    \n(Intercept)         &lt; 0.0000000000000002 ***\nt                   &lt; 0.0000000000000002 ***\nwarmth              &lt; 0.0000000000000002 ***\nphysical_punishment &lt; 0.0000000000000002 ***\nidentity                           0.385    \nintervention                0.0000000175 ***\nHDI                                0.970    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) t      warmth physc_ idntty intrvn\nt           -0.091                                   \nwarmth      -0.088 -0.002                            \nphyscl_pnsh -0.090 -0.007 -0.012                     \nidentity    -0.156  0.000 -0.013 -0.003              \ninterventin -0.055  0.000  0.039  0.019 -0.018       \nHDI         -0.941  0.000 -0.004  0.005  0.000  0.002\n\n\n\n\n5.4.0.4.2 Interactions With Time\n\nfit2B &lt;- lmer(outcome ~ t *(warmth + physical_punishment + \n               identity + intervention + HDI) +\n               (1 | country/id),\n             data = dfL)\n\nsummary(fit2B)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: \noutcome ~ t * (warmth + physical_punishment + identity + intervention +  \n    HDI) + (1 | country/id)\n   Data: dfL\n\nREML criterion at convergence: 57042.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7118 -0.6092 -0.0024  0.6150  3.6779 \n\nRandom effects:\n Groups     Name        Variance Std.Dev.\n id:country (Intercept)  8.436   2.905   \n country    (Intercept)  3.675   1.917   \n Residual               26.046   5.104   \nNumber of obs: 9000, groups:  id:country, 3000; country, 30\n\nFixed effects:\n                          Estimate   Std. Error           df t value\n(Intercept)             51.0036725    1.6087742   49.9583024  31.703\nt                        0.6989769    0.3746882 6131.2125222   1.865\nwarmth                   0.8170912    0.0805355 8274.9994610  10.146\nphysical_punishment     -1.0097729    0.1113557 8084.6085126  -9.068\nidentity                -0.2446453    0.3041604 8695.8966126  -0.804\nintervention             0.6604671    0.3046286 8697.0843469   2.168\nHDI                      0.0026692    0.0221295   36.1037721   0.121\nt:warmth                 0.0486211    0.0356217 6404.8722416   1.365\nt:physical_punishment    0.0004964    0.0494590 6753.0158846   0.010\nt:identity               0.0563140    0.1318043 5993.4518199   0.427\nt:intervention           0.0995037    0.1319917 5994.1433047   0.754\nt:HDI                   -0.0009379    0.0038233 5993.9091197  -0.245\n                                 Pr(&gt;|t|)    \n(Intercept)           &lt;0.0000000000000002 ***\nt                                  0.0622 .  \nwarmth                &lt;0.0000000000000002 ***\nphysical_punishment   &lt;0.0000000000000002 ***\nidentity                           0.4212    \nintervention                       0.0302 *  \nHDI                                0.9047    \nt:warmth                           0.1723    \nt:physical_punishment              0.9920    \nt:identity                         0.6692    \nt:intervention                     0.4510    \nt:HDI                              0.8062    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) t      warmth physc_ idntty intrvn HDI    t:wrmt t:phy_\nt           -0.466                                                        \nwarmth      -0.169  0.285                                                 \nphyscl_pnsh -0.183  0.313 -0.005                                          \nidentity    -0.278  0.450 -0.013 -0.002                                   \ninterventin -0.100  0.162  0.039  0.019 -0.017                            \nHDI         -0.892  0.230 -0.007  0.012 -0.001  0.003                     \nt:warmth     0.150 -0.324 -0.882  0.001  0.011 -0.035  0.006              \nt:physcl_pn  0.164 -0.351  0.004 -0.894 -0.001 -0.017 -0.010 -0.003       \nt:identity   0.242 -0.519  0.011  0.000 -0.867  0.014  0.001 -0.013  0.002\nt:intervntn  0.087 -0.187 -0.035 -0.017  0.014 -0.867 -0.003  0.041  0.019\nt:HDI        0.310 -0.666  0.015 -0.027  0.002 -0.007 -0.346 -0.016  0.029\n            t:dntt t:ntrv\nt                        \nwarmth                   \nphyscl_pnsh              \nidentity                 \ninterventin              \nHDI                      \nt:warmth                 \nt:physcl_pn              \nt:identity               \nt:intervntn -0.016       \nt:HDI       -0.002  0.008\n\n\n\n\n\n\n\n5.4.0.5 Get The Data\n\nusing Tables, MixedModels, StatFiles, DataFrames, CategoricalArrays, DataFramesMeta\n\ndfL = DataFrame(load(\"simulated_multilevel_longitudinal_data.dta\"))\n\n\n\n5.4.0.6 Run The Model\n\n5.4.0.6.1 Change Country To Categorical\n\n@transform!(dfL, :country = categorical(:country))\n\n\n\n5.4.0.6.2 Main Effects Only\n\nm2A = fit(MixedModel, @formula(outcome ~ t + warmth + \n                                 physical_punishment + \n                                 identity + intervention + \n                                 HDI +\n                                 (1 | country) + \n                                 (0 + warmth | country) +\n                                 (1 | id)), dfL)\n\nLinear mixed model fit by maximum likelihood\n outcome ~ 1 + t + warmth + physical_punishment + identity + intervention + HDI + (1 | country) + (0 + warmth | country) + (1 | id)\n    logLik   -2 logLik      AIC         AICc        BIC     \n -28499.6031  56999.2063  57021.2063  57021.2356  57099.3610\n\nVariance components:\n            Column    Variance Std.Dev.   Corr.\nid       (Intercept)   8.387351 2.896092\ncountry  (Intercept)   3.166939 1.779590\n         warmth        0.010760 0.103732   .  \nResidual              26.027290 5.101695\n Number of obs: 9000; levels of grouping factors: 3000, 30\n\n  Fixed-effects parameters:\n───────────────────────────────────────────────────────────────\n                            Coef.  Std. Error       z  Pr(&gt;|z|)\n───────────────────────────────────────────────────────────────\n(Intercept)          50.5949        1.35491     37.34    &lt;1e-99\nt                     0.943864      0.0658716   14.33    &lt;1e-45\nwarmth                0.913496      0.0423739   21.56    &lt;1e-99\nphysical_punishment  -1.0079        0.0497622  -20.25    &lt;1e-90\nidentity             -0.127692      0.151584    -0.84    0.3996\nintervention          0.858997      0.15191      5.65    &lt;1e-07\nHDI                  -0.000565882   0.0196433   -0.03    0.9770\n───────────────────────────────────────────────────────────────\n\n\n\n\n5.4.0.6.3 Interactions With Time\n\nm2B = fit(MixedModel, @formula(outcome ~ t * (warmth + \n                                 physical_punishment + \n                                 identity + intervention + \n                                   HDI) +\n                                 (1 | country) +\n                                 (0 + warmth | country) +\n                                 (1 | id)), dfL)\n\nLinear mixed model fit by maximum likelihood\n outcome ~ 1 + t + warmth + physical_punishment + identity + intervention + HDI + t & warmth + t & physical_punishment + t & identity + t & intervention + t & HDI + (1 | country) + (0 + warmth | country) + (1 | id)\n    logLik   -2 logLik      AIC         AICc        BIC     \n -28498.3091  56996.6182  57028.6182  57028.6788  57142.2979\n\nVariance components:\n            Column    Variance Std.Dev.   Corr.\nid       (Intercept)   8.391746 2.896851\ncountry  (Intercept)   3.170031 1.780458\n         warmth        0.010609 0.102999   .  \nResidual              26.015906 5.100579\n Number of obs: 9000; levels of grouping factors: 3000, 30\n\n  Fixed-effects parameters:\n──────────────────────────────────────────────────────────────────\n                                Coef.  Std. Error      z  Pr(&gt;|z|)\n──────────────────────────────────────────────────────────────────\n(Intercept)              51.0751       1.54284     33.10    &lt;1e-99\nt                         0.702771     0.374539     1.88    0.0606\nwarmth                    0.817076     0.0826636    9.88    &lt;1e-22\nphysical_punishment      -1.00903      0.111293    -9.07    &lt;1e-18\nidentity                 -0.238714     0.303996    -0.79    0.4323\nintervention              0.660761     0.30445      2.17    0.0300\nHDI                       0.00136065   0.0210842    0.06    0.9485\nt & warmth                0.0483635    0.0356074    1.36    0.1744\nt & physical_punishment   0.000542203  0.0494355    0.01    0.9912\nt & identity              0.0554385    0.131745     0.42    0.6739\nt & intervention          0.0992809    0.131925     0.75    0.4517\nt & HDI                  -0.000955067  0.00382162  -0.25    0.8027\n──────────────────────────────────────────────────────────────────",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Longitudinal Multilevel Models</span>"
    ]
  },
  {
    "objectID": "longitudinal-multilingual.html#interpretation",
    "href": "longitudinal-multilingual.html#interpretation",
    "title": "5  Longitudinal Multilevel Models",
    "section": "5.5 Interpretation",
    "text": "5.5 Interpretation\nThe main effects only model suggests that time is associated with increases in the outcome. In the main effects model, main effects other than time, indicate whether a particular variable is associated with higher or lower intercepts of the time trajectory, at the beginning of the study time. Warmth is again associated with increases in the outcome, while physical punishment is associated with decreases in the outcome. Identity is again not associated with the outcome, while the intervention is associated with higher levels of the outcome. The Human Development Index is again not associated with the outcome.\nThe second model adds interactions with time to the first model. Results are largly similar to the prior model. However, here we not only examine whether main effects other than time are associated with higher or lower time trajectories, but also whether particular variables are associated with differences in the slope of the time trajectory. In this case, we find that no independent variable is associated with changes in the slope of the time trajectory.\nHowever, it may be illustrative to imagine how we would interpret the results had a particular interaction term been statistically significant. Let us consider one of the interaction terms with the largest coefficient, intervention#time. The interaction of the intervention with time is positive. Had this coefficient been statistically signifcant, it would have indicated that the intervention was associated with more rapid increases in the outcome over time in addition to the fact that the intervention is associated with higher initial levels of the outcome.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Longitudinal Multilevel Models</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bates, D. (2024). MixedModels.jl\nDocumentation. https://juliastats.org/MixedModels.jl/stable/\n\n\nBates, D., Mächler, M., Bolker, B., & Walker, S. (2015). Fitting\nlinear mixed-effects models using lme4. Journal of Statistical\nSoftware, 67(1), 1–48. https://doi.org/10.18637/jss.v067.i01\n\n\nBezanson, J., Edelman, A., Karpinski, S., & Shah, V. B. (2017).\nJulia: A fresh approach to numerical computing. SIAM Review,\n59(1), 65–98. https://doi.org/10.1137/141000671\n\n\nR Core Team. (2023). R: A language and environment for statistical\ncomputing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nSchanen, J. (2021). Math person (Strogatz Prize\nentry). National Museum of Mathematics.\n\n\nStataCorp. (2021). Stata 17 multilevel mixed effects reference\nmanual. Stata Press.\n\n\nThoreau, H. D. (1975). The commercial spirit of modern times [1837]. In\nJ. J. Moldenhauer, E. Moser, & A. C. Kern (Eds.), Early essays\nand miscellanies. Princeton University Press.",
    "crumbs": [
      "References"
    ]
  }
]