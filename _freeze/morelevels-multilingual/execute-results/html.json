{
  "hash": "5f9115e0ba6a1a3e5ce83ca608ea64af",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"# Models With Three or More Levels and Cross-Classified Models\"\ndate: \"today\"\nformat:\n  pdf: \n    toc: true\n    toc-depth: 5\n  html:\n    toc: true\nbibliography: multilevel-multilingual.bib\n---\n\n::: {.cell}\n\n:::\n\n\n## Introduction\n\nA two level multilevel model imagines that *Level 1* units are nested in *Level 2* units. A three level multilevel model imagines that *Level 1* units are nested in *Level 2* units, which are in turn nested in *Level 3*. As more levels are added to the model (e.g. *Level 4*), we imagine all of these levels to be hierarchically nested.\n\nA *cross classified* model imagines that the nesting is not hierarchical, but rather that there are two sets of clusters or nestings in which individuals may be nested. \n\nBelow, I describe the use of Stata, R, and Julia to estimate these models.\n\n## Three Or More Levels {#sec-fourlevel}\n\n### The Data\n\nI use the *longitudinal* data from *Multilevel Thinking* (@sec-data) to which I have added an extra level of *United Nations Region* [@ArelBundock2018]. This data thus requires a four level model.\n\n### The Equation\n\n$$\\text{outcome}_{itjk} = \\beta_0 + \\beta_1 \\text{parental warmth}_{itjk} + \\beta_2 \\text{physical punishment}_{itjk} + \\beta_3 \\text{time}_{itjk} \\ + $$ {#eq-MLM-fourlevel-multilingual} \n\n$$\\beta_4 \\text{identity}_{itjk} + \\beta_5 \\text{intervention}_{itjk} + \\beta_6 \\text{HDI}_{itjk} +$$\n\n$$w_{0k} + u_{0j} + v_{0i} + e_{itjk}$$ \n\nHere we imagine $w_{0k}$ (region), $u_{0j}$ (country) and $v_{0i}$ (family) are hierarchically nested effects. \n\n\n### Run The Models\n\n::: {.panel-tabset group=\"language\"}\n\n#### Stata\n\n##### Get The Data\n\n\n::: {.cell collectcode='true'}\n\n```{.stata .cell-code}\n\nuse \"fourlevel.dta\", clear\n\n```\n:::\n\n\n##### Unconditional Model\n\n\n::: {.cell collectcode='true'}\n\n```{.stata .cell-code}\n\nmixed outcome || UNregion: || country: || family:\n\n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPerforming EM optimization ...\n\nPerforming gradient-based optimization: \nIteration 0:  Log likelihood = -29061.686  \nIteration 1:  Log likelihood = -29061.679  \nIteration 2:  Log likelihood = -29061.679  \n\nComputing standard errors ...\n\nMixed-effects ML regression                              Number of obs = 9,000\n\n        Grouping information\n        -------------------------------------------------------------\n                        |     No. of       Observations per group\n         Group variable |     groups    Minimum    Average    Maximum\n        ----------------+--------------------------------------------\n               UNregion |          5        600    1,800.0      3,600\n                country |         30        300      300.0        300\n                 family |      3,000          3        3.0          3\n        -------------------------------------------------------------\n\n                                                         Wald chi2(0)  =     .\nLog likelihood = -29061.679                              Prob > chi2   =     .\n\n------------------------------------------------------------------------------\n     outcome | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n       _cons |   54.05906    .987367    54.75   0.000     52.12385    55.99426\n------------------------------------------------------------------------------\n\n------------------------------------------------------------------------------\n  Random-effects parameters  |   Estimate   Std. err.     [95% conf. interval]\n-----------------------------+------------------------------------------------\nUNregion: Identity           |\n                  var(_cons) |   4.172687   3.187885      .9334852    18.65194\n-----------------------------+------------------------------------------------\ncountry: Identity            |\n                  var(_cons) |   2.849348   .8710225      1.565093    5.187414\n-----------------------------+------------------------------------------------\nfamily: Identity             |\n                  var(_cons) |   11.72403     .57475      10.64997    12.90641\n-----------------------------+------------------------------------------------\n               var(Residual) |   28.23424   .5154842      27.24177    29.26286\n------------------------------------------------------------------------------\nLR test vs. linear model: chi2(3) = 1843.44               Prob > chi2 = 0.0000\n\nNote: LR test is conservative and provided only for reference.\n```\n\n\n:::\n:::\n\n\n##### Conditional Model\n\n\n::: {.cell collectcode='true'}\n\n```{.stata .cell-code}\n\nmixed outcome t warmth physical_punishment i.identity i.intervention HDI ///\n|| UNregion: || country: || id:\n  \n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPerforming EM optimization ...\n\nPerforming gradient-based optimization: \nIteration 0:  Log likelihood = -28503.082  \nIteration 1:  Log likelihood = -28503.039  \nIteration 2:  Log likelihood = -28503.039  \n\nComputing standard errors ...\n\nMixed-effects ML regression                            Number of obs =   9,000\n\n        Grouping information\n        -------------------------------------------------------------\n                        |     No. of       Observations per group\n         Group variable |     groups    Minimum    Average    Maximum\n        ----------------+--------------------------------------------\n               UNregion |          5        600    1,800.0      3,600\n                country |         30        300      300.0        300\n                     id |      3,000          3        3.0          3\n        -------------------------------------------------------------\n\n                                                       Wald chi2(6)  = 1209.42\nLog likelihood = -28503.039                            Prob > chi2   =  0.0000\n\n-------------------------------------------------------------------------------------\n            outcome | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]\n--------------------+----------------------------------------------------------------\n                  t |   .9433791   .0658667    14.32   0.000     .8142827    1.072476\n             warmth |   .9140704   .0379156    24.11   0.000     .8397571    .9883837\nphysical_punishment |  -1.008615   .0497772   -20.26   0.000    -1.106176   -.9110531\n         1.identity |  -.1332133   .1516437    -0.88   0.380    -.4304294    .1640028\n     1.intervention |   .8589263   .1519619     5.65   0.000     .5610865    1.156766\n                HDI |   .0148561   .0196605     0.76   0.450    -.0236777    .0533899\n              _cons |   50.16426   1.675219    29.94   0.000     46.88089    53.44763\n-------------------------------------------------------------------------------------\n\n------------------------------------------------------------------------------\n  Random-effects parameters  |   Estimate   Std. err.     [95% conf. interval]\n-----------------------------+------------------------------------------------\nUNregion: Identity           |\n                  var(_cons) |   4.722007   3.585939      1.065898    20.91884\n-----------------------------+------------------------------------------------\ncountry: Identity            |\n                  var(_cons) |   2.863495   .8656459      1.583342    5.178668\n-----------------------------+------------------------------------------------\nid: Identity                 |\n                  var(_cons) |   8.421131   .4711947      7.546445    9.397199\n-----------------------------+------------------------------------------------\n               var(Residual) |   26.02919   .4752587      25.11417    26.97755\n------------------------------------------------------------------------------\nLR test vs. linear model: chi2(3) = 1844.00               Prob > chi2 = 0.0000\n\nNote: LR test is conservative and provided only for reference.\n```\n\n\n:::\n:::\n\n\n#### R\n\n##### Get The Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(haven)\n\ndf4 <- read_dta(\"fourlevel.dta\")\n```\n:::\n\n\n##### Change Some Variables To Categorical\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf4$identity <- factor(df4$identity)\n\ndf4$intervention <- factor(df4$intervention)\n```\n:::\n\n\n##### Unconditional Model\n\n::: {.callout-caution collapse=\"false\"}\n`lme4` does not directly provide p values in results, because of some disagreement over exactly how these p values should be calculated. Therefore, in this Appendix, I also call library `lmerTest` to provide p values for `lme4` results.\n:::\n\n::: {.callout-tip}\nR prefers to use scientific notation when possible. I find that the use of scientific notation can be confusing in reading results. I turn off scientific notation by setting a penalty for its use:  `options(scipen = 999)`.  \n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4) \n\nlibrary(lmerTest)\n\noptions(scipen = 999) \n\nfit4A <- lmer(outcome ~  (1 | UNregion/country/id),\n             data = df4)\n\nsummary(fit4A)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: outcome ~ (1 | UNregion/country/id)\n   Data: df4\n\nREML criterion at convergence: 58121.4\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7850 -0.6064 -0.0047  0.6020  3.4399 \n\nRandom effects:\n Groups                Name        Variance Std.Dev.\n id:(country:UNregion) (Intercept) 11.724   3.424   \n country:UNregion      (Intercept)  2.842   1.686   \n UNregion              (Intercept)  5.478   2.340   \n Residual                          28.234   5.314   \nNumber of obs: 9000, groups:  \nid:(country:UNregion), 3000; country:UNregion, 30; UNregion, 5\n\nFixed effects:\n            Estimate Std. Error     df t value   Pr(>|t|)    \n(Intercept)   54.061      1.112  3.777    48.6 0.00000201 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n##### Conditional Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit4B <- lmer(outcome ~ t + warmth + physical_punishment + \n                identity + intervention + HDI + \n                (1 | UNregion/country/id),\n              data = df4)\n\nsummary(fit4B)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: \noutcome ~ t + warmth + physical_punishment + identity + intervention +  \n    HDI + (1 | UNregion/country/id)\n   Data: df4\n\nREML criterion at convergence: 57026.4\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6846 -0.6096 -0.0038  0.6138  3.6850 \n\nRandom effects:\n Groups                Name        Variance Std.Dev.\n id:(country:UNregion) (Intercept)  8.438   2.905   \n country:UNregion      (Intercept)  2.979   1.726   \n UNregion              (Intercept)  6.178   2.486   \n Residual                          26.036   5.103   \nNumber of obs: 9000, groups:  \nid:(country:UNregion), 3000; country:UNregion, 30; UNregion, 5\n\nFixed effects:\n                      Estimate Std. Error         df t value\n(Intercept)           50.11857    1.78086   15.79112  28.143\nt                      0.94338    0.06588 5998.37756  14.321\nwarmth                 0.91406    0.03793 4745.28492  24.096\nphysical_punishment   -1.00876    0.04980 6483.46337 -20.257\nidentity1             -0.13324    0.15173 2969.00938  -0.878\nintervention1          0.85872    0.15205 2971.85430   5.648\nHDI                    0.01560    0.02006   24.39852   0.778\n                                Pr(>|t|)    \n(Intercept)          0.00000000000000641 ***\nt                   < 0.0000000000000002 ***\nwarmth              < 0.0000000000000002 ***\nphysical_punishment < 0.0000000000000002 ***\nidentity1                          0.380    \nintervention1        0.00000001780521096 ***\nHDI                                0.444    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) t      warmth physc_ idntt1 intrv1\nt           -0.073                                   \nwarmth      -0.071 -0.002                            \nphyscl_pnsh -0.073 -0.007 -0.012                     \nidentity1   -0.040  0.000 -0.013 -0.003              \ninterventn1 -0.045  0.000  0.039  0.019 -0.018       \nHDI         -0.738  0.000 -0.005  0.005 -0.001  0.001\n```\n\n\n:::\n:::\n\n\n#### Julia\n\n##### Get The Data\n\n\n::: {.cell}\n\n```{.julia .cell-code}\nusing Tables, MixedModels, StatFiles, DataFrames, CategoricalArrays, DataFramesMeta\n\ndf4 = DataFrame(load(\"fourlevel.dta\"))\n```\n:::\n\n\n##### Change Some Variables To Categorical\n\n\n::: {.cell}\n\n```{.julia .cell-code}\n@transform!(df4, :country = categorical(:country))\n\n@transform!(df4, :UNregion = categorical(:UNregion))\n\n@transform!(df4, :identity = categorical(:identity))\n\n@transform!(df4, :intervention = categorical(:intervention))\n\n```\n:::\n\n\n##### Unconditional Model\n\n\n::: {.cell}\n\n```{.julia .cell-code}\nm4A = fit(MixedModel, @formula(outcome ~ t + warmth + \n                                  physical_punishment + \n                                  identity + intervention + \n                                  HDI +\n                                  (1 | UNregion) + \n                                  (1 | country) + \n                                  (1 | id)), df4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by maximum likelihood\n outcome ~ 1 + t + warmth + physical_punishment + identity + intervention + HDI + (1 | UNregion) + (1 | country) + (1 | id)\n    logLik   -2 logLik      AIC         AICc        BIC     \n -28503.0394  57006.0787  57028.0787  57028.1081  57106.2335\n\nVariance components:\n            Column   Variance Std.Dev.\nid       (Intercept)   8.42110 2.90191\ncountry  (Intercept)   2.86347 1.69218\nUNregion (Intercept)   4.72082 2.17274\nResidual              26.02921 5.10188\n Number of obs: 9000; levels of grouping factors: 3000, 30, 5\n\n  Fixed-effects parameters:\n─────────────────────────────────────────────────────────────\n                          Coef.  Std. Error       z  Pr(>|z|)\n─────────────────────────────────────────────────────────────\n(Intercept)          50.1643      1.67514     29.95    <1e-99\nt                     0.943379    0.0658668   14.32    <1e-45\nwarmth                0.91407     0.0379156   24.11    <1e-99\nphysical_punishment  -1.00861     0.0497772  -20.26    <1e-90\nidentity             -0.133213    0.151644    -0.88    0.3797\nintervention          0.858927    0.151962     5.65    <1e-07\nHDI                   0.0148553   0.0196604    0.76    0.4499\n─────────────────────────────────────────────────────────────\n```\n\n\n:::\n:::\n\n\n##### Conditional Model\n\n\n::: {.cell}\n\n```{.julia .cell-code}\nm4B = fit(MixedModel, @formula(outcome ~ t + warmth + \n                                  physical_punishment + \n                                  identity + intervention + \n                                  HDI +\n                                  (1 | UNregion) + \n                                  (1 | country) + \n                                  (1 | id)), df4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by maximum likelihood\n outcome ~ 1 + t + warmth + physical_punishment + identity + intervention + HDI + (1 | UNregion) + (1 | country) + (1 | id)\n    logLik   -2 logLik      AIC         AICc        BIC     \n -28503.0394  57006.0787  57028.0787  57028.1081  57106.2335\n\nVariance components:\n            Column   Variance Std.Dev.\nid       (Intercept)   8.42110 2.90191\ncountry  (Intercept)   2.86347 1.69218\nUNregion (Intercept)   4.72082 2.17274\nResidual              26.02921 5.10188\n Number of obs: 9000; levels of grouping factors: 3000, 30, 5\n\n  Fixed-effects parameters:\n─────────────────────────────────────────────────────────────\n                          Coef.  Std. Error       z  Pr(>|z|)\n─────────────────────────────────────────────────────────────\n(Intercept)          50.1643      1.67514     29.95    <1e-99\nt                     0.943379    0.0658668   14.32    <1e-45\nwarmth                0.91407     0.0379156   24.11    <1e-99\nphysical_punishment  -1.00861     0.0497772  -20.26    <1e-90\nidentity             -0.133213    0.151644    -0.88    0.3797\nintervention          0.858927    0.151962     5.65    <1e-07\nHDI                   0.0148553   0.0196604    0.76    0.4499\n─────────────────────────────────────────────────────────────\n```\n\n\n:::\n:::\n\n\n:::\n\n### Interpretation\n\nThere is group level variation attributable to individual, country, and region.\n\nAs in other models, parental warmth, and participation in the intervention are associated with increases in the outcome. Parental use of physical punishment is associated with decreases in the outcome.\n\n## Cross-Classified Models\n\n### The Data\n\nI use the *cross-sectional* data from *Multilevel Thinking* (@sec-data) to which I have added an extra level of a hypothetical language. \n\n### The Equation\n\n$$\\text{outcome}_{ijm} = \\beta_0 + \\beta_1 \\text{parental warmth}_{ijm} + \\beta_2 \\text{physical punishment}_{ijm} + \\beta_3 \\text{time}_{ijm} \\ + $$ {#eq-crossclassified-multilingual}\n\n$$\\beta_4 \\text{identity}_{ijm} + \\beta_5 \\text{intervention}_{ijm} + \\beta_6 \\text{HDI}_{ijm} +$$ \n\n$$u_{0j} + m_{0m} + e_{ijm}$$ \n\nHere $u_{0j}$ (country) and $m_{0m}$ (language) are not nested hierarchically, but are *cross classified*.\n\n### Run The Models\n\n::: {.panel-tabset group=\"language\"}\n\n#### Stata\n\n##### Get The Data\n\n\n::: {.cell collectcode='true'}\n\n```{.stata .cell-code}\n\nuse \"crossclassified.dta\", clear\n\n```\n:::\n\n\n##### Unconditional Model\n\n\n::: {.cell}\n\n```{.stata .cell-code}\n\nmixed outcome || _all: R.country || _all: R.language\n\n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPerforming EM optimization ...\n\nPerforming gradient-based optimization: \nIteration 0:  Log likelihood = -9835.8123  \nIteration 1:  Log likelihood = -9835.8111  \nIteration 2:  Log likelihood = -9835.8111  \n\nComputing standard errors ...\n\nMixed-effects ML regression                         Number of obs    =   3,000\nGroup variable: _all                                Number of groups =       1\n                                                    Obs per group:\n                                                                 min =   3,000\n                                                                 avg = 3,000.0\n                                                                 max =   3,000\n                                                    Wald chi2(0)     =       .\nLog likelihood = -9835.8111                         Prob > chi2      =       .\n\n---------------------------------------------------------------------------------\n        outcome | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]\n----------------+----------------------------------------------------------------\n          _cons |   52.43187   .3590214   146.04   0.000      51.7282    53.13554\n---------------------------------------------------------------------------------\n\n------------------------------------------------------------------------------\n  Random-effects parameters  |   Estimate   Std. err.     [95% conf. interval]\n-----------------------------+------------------------------------------------\n_all: Identity               |\n              var(R.country) |   3.177791   .9244633      1.796798    5.620198\n-----------------------------+------------------------------------------------\n_all: Identity               |\n             var(R.language) |   .9566314   .3284087      .4881235     1.87482\n-----------------------------+------------------------------------------------\n               var(Residual) |   39.62877   1.045619      37.63148    41.73206\n------------------------------------------------------------------------------\nLR test vs. linear model: chi2(2) = 180.84                Prob > chi2 = 0.0000\n\nNote: LR test is conservative and provided only for reference.\n```\n\n\n:::\n:::\n\n\n##### Conditional Model\n\n\n::: {.cell}\n\n```{.stata .cell-code}\n\nmixed outcome warmth physical_punishment i.identity i.intervention HDI || _all: R.country || _all: R.language\n\n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPerforming EM optimization ...\n\nPerforming gradient-based optimization: \nIteration 0:  Log likelihood = -9663.2195  \nIteration 1:  Log likelihood = -9663.2194  \n\nComputing standard errors ...\n\nMixed-effects ML regression                         Number of obs    =   3,000\nGroup variable: _all                                Number of groups =       1\n                                                    Obs per group:\n                                                                 min =   3,000\n                                                                 avg = 3,000.0\n                                                                 max =   3,000\n                                                    Wald chi2(5)     =  367.04\nLog likelihood = -9663.2194                         Prob > chi2      =  0.0000\n\n-------------------------------------------------------------------------------------\n            outcome | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]\n--------------------+----------------------------------------------------------------\n             warmth |   .8331461   .0579811    14.37   0.000     .7195052     .946787\nphysical_punishment |  -.9979749    .080268   -12.43   0.000    -1.155297   -.8406525\n         1.identity |  -.2922428   .2191421    -1.33   0.182    -.7217534    .1372678\n     1.intervention |   .6097458   .2195139     2.78   0.005     .1795064    1.039985\n                HDI |  -.0015879   .0204157    -0.08   0.938    -.0416021    .0384262\n              _cons |   51.92255   1.411069    36.80   0.000     49.15691     54.6882\n-------------------------------------------------------------------------------------\n\n------------------------------------------------------------------------------\n  Random-effects parameters  |   Estimate   Std. err.     [95% conf. interval]\n-----------------------------+------------------------------------------------\n_all: Identity               |\n              var(R.country) |   3.361218   .9603072      1.920024    5.884192\n-----------------------------+------------------------------------------------\n_all: Identity               |\n             var(R.language) |   1.121946   .3269535      .6337502    1.986214\n-----------------------------+------------------------------------------------\n               var(Residual) |   35.11959   .9263999      33.35002    36.98306\n------------------------------------------------------------------------------\nLR test vs. linear model: chi2(2) = 227.02                Prob > chi2 = 0.0000\n\nNote: LR test is conservative and provided only for reference.\n```\n\n\n:::\n:::\n\n\n#### R\n\n##### Get The Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(haven)\n\ndfCC <- read_dta(\"crossclassified.dta\")\n```\n:::\n\n\n##### Change Some Variables To Categorical\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndfCC$identity <- factor(dfCC$identity)\n\ndfCC$intervention <- factor(dfCC$intervention)\n```\n:::\n\n\n##### Unconditional Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4) \n\nlibrary(lmerTest)\n\noptions(scipen = 999) \n\nfitCC_A <- lmer(outcome ~  \n                 (1 | country) +\n                 (1 | language),\n             data = dfCC)\n\nsummary(fitCC_A)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: outcome ~ (1 | country) + (1 | language)\n   Data: dfCC\n\nREML criterion at convergence: 19671.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.3899 -0.6602 -0.0104  0.6798  3.6924 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n language (Intercept)  0.9604  0.980   \n country  (Intercept)  3.2919  1.814   \n Residual             39.6276  6.295   \nNumber of obs: 3000, groups:  language, 100; country, 30\n\nFixed effects:\n            Estimate Std. Error      df t value            Pr(>|t|)    \n(Intercept)  52.4319     0.3643 33.4284   143.9 <0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n##### Conditional Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfitCC_B <- lmer(outcome ~ t + warmth + physical_punishment + \n                identity + intervention + HDI + \n                (1 | country) +\n                (1 | language),\n              data = dfCC)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in model.frame.default(data = dfCC, drop.unused.levels = TRUE, formula = outcome ~ : invalid type (closure) for variable 't'\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fitCC_B)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': object 'fitCC_B' not found\n```\n\n\n:::\n:::\n\n\n#### Julia\n\n##### Get The Data\n\n\n::: {.cell}\n\n```{.julia .cell-code}\nusing Tables, MixedModels, StatFiles, DataFrames, CategoricalArrays, DataFramesMeta\n\ndfCC = DataFrame(load(\"crossclassified.dta\"))\n```\n:::\n\n\n##### Change Some Variables To Categorical\n\n\n::: {.cell}\n\n```{.julia .cell-code}\n@transform!(dfCC, :country = categorical(:country))\n\n@transform!(dfCC, :language = categorical(:language))\n\n@transform!(dfCC, :identity = categorical(:identity))\n\n@transform!(dfCC, :intervention = categorical(:intervention))\n\n```\n:::\n\n\n##### Unconditional Model\n\n\n::: {.cell}\n\n```{.julia .cell-code}\nmCCA = fit(MixedModel, @formula(outcome ~ \n                                 (1 | country) + \n                                 (1 | language)), dfCC)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by maximum likelihood\n outcome ~ 1 + (1 | country) + (1 | language)\n   logLik   -2 logLik     AIC       AICc        BIC    \n -9835.8111 19671.6222 19679.6222 19679.6356 19703.6477\n\nVariance components:\n            Column    Variance Std.Dev. \nlanguage (Intercept)   0.956631 0.978075\ncountry  (Intercept)   3.177768 1.782629\nResidual              39.628773 6.295139\n Number of obs: 3000; levels of grouping factors: 100, 30\n\n  Fixed-effects parameters:\n──────────────────────────────────────────────────\n               Coef.  Std. Error       z  Pr(>|z|)\n──────────────────────────────────────────────────\n(Intercept)  52.4319     0.35902  146.04    <1e-99\n──────────────────────────────────────────────────\n```\n\n\n:::\n:::\n\n\n##### Conditional Model\n\n\n::: {.cell}\n\n```{.julia .cell-code}\nmCCA = fit(MixedModel, @formula(outcome ~ warmth + \n                                 physical_punishment + \n                                 identity + intervention + \n                                 HDI +\n                                 (1 | country) + \n                                 (1 | language)), dfCC)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by maximum likelihood\n outcome ~ 1 + warmth + physical_punishment + identity + intervention + HDI + (1 | country) + (1 | language)\n   logLik   -2 logLik     AIC       AICc        BIC    \n -9663.2194 19326.4388 19344.4388 19344.4990 19398.4962\n\nVariance components:\n            Column   Variance Std.Dev.\nlanguage (Intercept)   1.12193 1.05921\ncountry  (Intercept)   3.36119 1.83335\nResidual              35.11960 5.92618\n Number of obs: 3000; levels of grouping factors: 100, 30\n\n  Fixed-effects parameters:\n──────────────────────────────────────────────────────────────\n                           Coef.  Std. Error       z  Pr(>|z|)\n──────────────────────────────────────────────────────────────\n(Intercept)          51.9226       1.41106     36.80    <1e-99\nwarmth                0.833146     0.0579811   14.37    <1e-46\nphysical_punishment  -0.997975     0.080268   -12.43    <1e-34\nidentity             -0.292243     0.219142    -1.33    0.1823\nintervention          0.609746     0.219514     2.78    0.0055\nHDI                  -0.00158794   0.0204156   -0.08    0.9380\n──────────────────────────────────────────────────────────────\n```\n\n\n:::\n:::\n\n\n:::\n\n### Interpretation\n\nThere is group level variation attributable to both language and country.\n\nAs in other models, parental warmth, and participation in the intervention are associated with increases in the outcome. Parental use of physical punishment is associated with decreases in the outcome.\n\n",
    "supporting": [
      "morelevels-multilingual_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}