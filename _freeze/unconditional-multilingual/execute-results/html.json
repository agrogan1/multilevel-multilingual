{
  "hash": "6164937f01ee4f314bcfed7cc7c6119c",
  "result": {
    "engine": "knitr",
    "markdown": "# Unconditional Model\n\n## Two Level Model\n\nAn *unconditional* multilevel model is a model with no independent variables. One should always run an unconditional model as the first step of a multilevel model in order to get a sense of the way that variation is apportioned in the model across the different levels.\n\n### The Equation\n\n$$\\text{outcome}_{ij}= \\beta_0 + u_{0j} + e_{ij}$$ {#eq-MLMunconditional}\n\nThe Intraclass Correlation Coefficient (ICC) is given by:\n\n$$\\text{ICC} = \\frac{var(u_{0j})}{var(u_{0j}) + var(e_{ij})}$$ {#eq-ICCunconditional}\n\nIn a two level multilevel model, the ICC provides a measure of the proportion of variation attributable to Level 2.\n\n\n::: {.cell}\n\n:::\n\n\n### Run Models\n\n::: {.panel-tabset group=\"language\"}\n\n#### Stata\n\n\n::: {.cell collectcode='true'}\n\n```{.stata .cell-code}\n\nuse simulated_multilevel_data.dta // use data\n\n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\ninvalid syntax\nr(198);\n```\n\n\n:::\n:::\n\n::: {.cell collectcode='true'}\n\n```{.stata .cell-code}\n\nmixed outcome || country: id: // unconditional model\n  \n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\ninvalid syntax\nr(198);\n\n\ninvalid syntax\nr(198);\n\nr(198);\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.stata .cell-code}\n  \nestat icc // ICC\n\n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\ninvalid syntax\nr(198);\n\n\nlast estimates not found\nr(301);\n\nr(301);\n```\n\n\n:::\n:::\n\n\n#### R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(haven)\n\ndf <- read_dta(\"simulated_multilevel_data.dta\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4) # estimate multilevel models\n\nfit0 <- lmer(outcome ~ (1 | country),\n             data = df) # unconditional model\n\nsummary(fit0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: outcome ~ (1 | country)\n   Data: df\n\nREML criterion at convergence: 19605.9\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.3844 -0.6655 -0.0086  0.6725  3.6626 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n country  (Intercept)  3.302   1.817   \n Residual             39.461   6.282   \nNumber of obs: 3000, groups:  country, 30\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)   52.433      0.351   149.4\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(performance)\n\nperformance::icc(fit0) # ICC\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Intraclass Correlation Coefficient\n\n    Adjusted ICC: 0.077\n  Unadjusted ICC: 0.077\n```\n\n\n:::\n:::\n\n\n#### Julia\n\n\n::: {.cell}\n\n```{.julia .cell-code}\nusing Tables, MixedModels, MixedModelsExtras, \nStatFiles, DataFrames, CategoricalArrays, DataFramesMeta\n\ndf = DataFrame(load(\"simulated_multilevel_data.dta\"))\n```\n:::\n\n::: {.cell}\n\n```{.julia .cell-code}\n@transform!(df, :country = categorical(:country))\n```\n:::\n\n::: {.cell}\n\n```{.julia .cell-code}\n\nm0 = fit(MixedModel, \n         @formula(outcome ~ (1 | country)), df) # unconditional model\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by maximum likelihood\n outcome ~ 1 + (1 | country)\n   logLik   -2 logLik     AIC       AICc        BIC    \n -9802.8371 19605.6742 19611.6742 19611.6822 19629.6933\n\nVariance components:\n            Column   Variance Std.Dev.\ncountry  (Intercept)   3.17863 1.78287\nResidual              39.46106 6.28180\n Number of obs: 3000; levels of grouping factors: 30\n\n  Fixed-effects parameters:\n──────────────────────────────────────────────────\n               Coef.  Std. Error       z  Pr(>|z|)\n──────────────────────────────────────────────────\n(Intercept)  52.4333    0.345121  151.93    <1e-99\n──────────────────────────────────────────────────\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.julia .cell-code}\n\nicc(m0) # ICC\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0.07454637475695493\n```\n\n\n:::\n:::\n\n\n:::\n\n### Interpretation\n\nIn each case, the software finds that nearly 8% of the variation in the outcome is explainable by the clustering of the observations in each country.\n\n## Three Level Model\n\n### The Equation\n\n$$\\text{outcome}_{ij}= \\beta_0 + u_{0j} + v_{0i} + e_{ij}$$ {#eq-MLMunconditional3}\n\nAs discussed in the main text, in a three level model, there are two intraclass correlation coefficients [@StataCorp2023]. The formulas for the Intraclass Correlation Coefficient (ICC) are given by [@StataCorp2023]:\n\n$$\\text{ICC} = \\frac{var(u_{0j})}{var(u_{0j}) + var(v_{0i}) + var(e_{ij})}$$ {#eq-ICCunconditional3A}\n\nAgain, following @StataCorp2023, @eq-ICCunconditional3A is the correlation of responses for person-timepoints from the same country but different persons.\n\n$$\\text{ICC} = \\frac{var(u_{0j}) + var(v_{0i})}{var(u_{0j}) + var(v_{0i}) + var(e_{ij})}$$ {#eq-ICCunconditional3B}\n\nAgain, closely following @StataCorp2023, @eq-ICCunconditional3B is the correlation of responses for person-timepoints from the same country and same person.\n\n### Run Models\n\n::: {.panel-tabset group=\"language\"}\n\n#### Stata\n\n\n::: {.cell collectcode='true'}\n\n```{.stata .cell-code}\n\nuse simulated_multilevel_longitudinal_data.dta // use data\n\n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\ninvalid syntax\nr(198);\n```\n\n\n:::\n:::\n\n::: {.cell collectcode='true'}\n\n```{.stata .cell-code}\n\nmixed outcome || country: || id:  // unconditional model\n  \n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\ninvalid syntax\nr(198);\n\n\n\nPerforming EM optimization ...\n\nPerforming gradient-based optimization: \nIteration 0:  Log likelihood = -9802.8371  (not concave)\nIteration 1:  Log likelihood = -9802.8371  (not concave)\nIteration 2:  Log likelihood = -9802.8371  (not concave)\nIteration 3:  Log likelihood = -9802.8371  (backed up)\nIteration 4:  Log likelihood = -9802.8371  (backed up)\nIteration 5:  Log likelihood = -9802.8371  (backed up)\nIteration 6:  Log likelihood = -9802.8371  (backed up)\nIteration 7:  Log likelihood = -9802.8371  (backed up)\nIteration 8:  Log likelihood = -9802.8371  (backed up)\nIteration 9:  Log likelihood = -9802.8371  (backed up)\nIteration 10: Log likelihood = -9802.8371  (backed up)\nIteration 11: Log likelihood = -9802.8371  (backed up)\nIteration 12: Log likelihood = -9802.8371  (backed up)\nIteration 13: Log likelihood = -9802.8371  (backed up)\nIteration 14: Log likelihood = -9802.8371  (backed up)\nIteration 15: Log likelihood = -9802.8371  (backed up)\nIteration 16: Log likelihood = -9802.8371  (backed up)\nIteration 17: Log likelihood = -9802.8371  (backed up)\nIteration 18: Log likelihood = -9802.8371  (backed up)\nIteration 19: Log likelihood = -9802.8371  (backed up)\nIteration 20: Log likelihood = -9802.8371  (backed up)\nIteration 21: Log likelihood = -9802.8371  (backed up)\nIteration 22: Log likelihood = -9802.8371  (backed up)\nIteration 23: Log likelihood = -9802.8371  (backed up)\nIteration 24: Log likelihood = -9802.8371  (backed up)\nIteration 25: Log likelihood = -9802.8371  (backed up)\nIteration 26: Log likelihood = -9802.8371  (backed up)\nIteration 27: Log likelihood = -9802.8371  (backed up)\nIteration 28: Log likelihood = -9802.8371  (backed up)\nIteration 29: Log likelihood = -9802.8371  (backed up)\nIteration 30: Log likelihood = -9802.8371  (backed up)\nIteration 31: Log likelihood = -9802.8371  (backed up)\nIteration 32: Log likelihood = -9802.8371  (backed up)\nIteration 33: Log likelihood = -9802.8371  (backed up)\nIteration 34: Log likelihood = -9802.8371  (backed up)\nIteration 35: Log likelihood = -9802.8371  (backed up)\nIteration 36: Log likelihood = -9802.8371  (backed up)\nIteration 37: Log likelihood = -9802.8371  (backed up)\nIteration 38: Log likelihood = -9802.8371  (backed up)\nIteration 39: Log likelihood = -9802.8371  (backed up)\nIteration 40: Log likelihood = -9802.8371  (backed up)\nIteration 41: Log likelihood = -9802.8371  (backed up)\nIteration 42: Log likelihood = -9802.8371  (backed up)\nIteration 43: Log likelihood = -9802.8371  (backed up)\nIteration 44: Log likelihood = -9802.8371  (backed up)\nIteration 45: Log likelihood = -9802.8371  (backed up)\nIteration 46: Log likelihood = -9802.8371  (backed up)\nIteration 47: Log likelihood = -9802.8371  (backed up)\nIteration 48: Log likelihood = -9802.8371  (backed up)\nIteration 49: Log likelihood = -9802.8371  (backed up)\nIteration 50: Log likelihood = -9802.8371  (backed up)\nIteration 51: Log likelihood = -9802.8371  (backed up)\nIteration 52: Log likelihood = -9802.8371  (backed up)\nIteration 53: Log likelihood = -9802.8371  (backed up)\nIteration 54: Log likelihood = -9802.8371  (backed up)\nIteration 55: Log likelihood = -9802.8371  (backed up)\nIteration 56: Log likelihood = -9802.8371  (backed up)\nIteration 57: Log likelihood = -9802.8371  (backed up)\nIteration 58: Log likelihood = -9802.8371  (backed up)\nIteration 59: Log likelihood = -9802.8371  (backed up)\nIteration 60: Log likelihood = -9802.8371  (backed up)\nIteration 61: Log likelihood = -9802.8371  (backed up)\nIteration 62: Log likelihood = -9802.8371  (backed up)\nIteration 63: Log likelihood = -9802.8371  (backed up)\nIteration 64: Log likelihood = -9802.8371  (backed up)\nIteration 65: Log likelihood = -9802.8371  (backed up)\nIteration 66: Log likelihood = -9802.8371  (backed up)\nIteration 67: Log likelihood = -9802.8371  (backed up)\nIteration 68: Log likelihood = -9802.8371  (backed up)\nIteration 69: Log likelihood = -9802.8371  (backed up)\nIteration 70: Log likelihood = -9802.8371  (backed up)\nIteration 71: Log likelihood = -9802.8371  (backed up)\nIteration 72: Log likelihood = -9802.8371  (backed up)\nIteration 73: Log likelihood = -9802.8371  (backed up)\nIteration 74: Log likelihood = -9802.8371  (backed up)\nIteration 75: Log likelihood = -9802.8371  (backed up)\nIteration 76: Log likelihood = -9802.8371  (backed up)\nIteration 77: Log likelihood = -9802.8371  (backed up)\nIteration 78: Log likelihood = -9802.8371  (backed up)\nIteration 79: Log likelihood = -9802.8371  (backed up)\nIteration 80: Log likelihood = -9802.8371  (backed up)\nIteration 81: Log likelihood = -9802.8371  (backed up)\nIteration 82: Log likelihood = -9802.8371  (backed up)\nIteration 83: Log likelihood = -9802.8371  (backed up)\nIteration 84: Log likelihood = -9802.8371  (backed up)\nIteration 85: Log likelihood = -9802.8371  (backed up)\nIteration 86: Log likelihood = -9802.8371  (backed up)\nIteration 87: Log likelihood = -9802.8371  (backed up)\nIteration 88: Log likelihood = -9802.8371  (backed up)\nIteration 89: Log likelihood = -9802.8371  (backed up)\nIteration 90: Log likelihood = -9802.8371  (backed up)\nIteration 91: Log likelihood = -9802.8371  (backed up)\nIteration 92: Log likelihood = -9802.8371  (backed up)\nIteration 93: Log likelihood = -9802.8371  (backed up)\nIteration 94: Log likelihood = -9802.8371  (backed up)\nIteration 95: Log likelihood = -9802.8371  (backed up)\nIteration 96: Log likelihood = -9802.8371  (backed up)\nIteration 97: Log likelihood = -9802.8371  (backed up)\nIteration 98: Log likelihood = -9802.8371  (backed up)\nIteration 99: Log likelihood = -9802.8371  (backed up)\nIteration 100: Log likelihood = -9802.8371  (backed up)\nIteration 101: Log likelihood = -9802.8371  (backed up)\nIteration 102: Log likelihood = -9802.8371  (backed up)\nIteration 103: Log likelihood = -9802.8371  (backed up)\nIteration 104: Log likelihood = -9802.8371  (backed up)\nIteration 105: Log likelihood = -9802.8371  (backed up)\nIteration 106: Log likelihood = -9802.8371  (backed up)\nIteration 107: Log likelihood = -9802.8371  (backed up)\nIteration 108: Log likelihood = -9802.8371  (backed up)\nIteration 109: Log likelihood = -9802.8371  (backed up)\nIteration 110: Log likelihood = -9802.8371  (backed up)\nIteration 111: Log likelihood = -9802.8371  (backed up)\nIteration 112: Log likelihood = -9802.8371  (backed up)\nIteration 113: Log likelihood = -9802.8371  (backed up)\nIteration 114: Log likelihood = -9802.8371  (backed up)\nIteration 115: Log likelihood = -9802.8371  (backed up)\nIteration 116: Log likelihood = -9802.8371  (backed up)\nIteration 117: Log likelihood = -9802.8371  (backed up)\nIteration 118: Log likelihood = -9802.8371  (backed up)\nIteration 119: Log likelihood = -9802.8371  (backed up)\nIteration 120: Log likelihood = -9802.8371  (backed up)\nIteration 121: Log likelihood = -9802.8371  (backed up)\nIteration 122: Log likelihood = -9802.8371  (backed up)\nIteration 123: Log likelihood = -9802.8371  (backed up)\nIteration 124: Log likelihood = -9802.8371  (backed up)\nIteration 125: Log likelihood = -9802.8371  (backed up)\nIteration 126: Log likelihood = -9802.8371  (backed up)\nIteration 127: Log likelihood = -9802.8371  (backed up)\nIteration 128: Log likelihood = -9802.8371  (backed up)\n--Break--\nr(1);\n\n--Break--\nr(1);\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.stata .cell-code}\n  \nestat icc // ICC\n\n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\ninvalid syntax\nr(198);\n\n\nlast estimates not found\nr(301);\n\nr(301);\n```\n\n\n:::\n:::\n\n\n#### R\n\nIn R, the ICC for a three level model is easiest to estimate \"by hand\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(haven)\n\ndfL <- read_dta(\"simulated_multilevel_longitudinal_data.dta\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4) # estimate multilevel models\n\nfit0L <- lmer(outcome ~ (1 | country/id),\n             data = dfL) # unconditional model\n\nsummary(fit0L)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: outcome ~ (1 | country/id)\n   Data: dfL\n\nREML criterion at convergence: 58116.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7858 -0.6059 -0.0062  0.6017  3.4348 \n\nRandom effects:\n Groups     Name        Variance Std.Dev.\n id:country (Intercept) 11.724   3.424   \n country    (Intercept)  3.351   1.830   \n Residual               28.234   5.314   \nNumber of obs: 9000, groups:  id:country, 3000; country, 30\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  53.3777     0.3446   154.9\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n3.351 / (11.724 + 3.351 + 28.234)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.07737422\n```\n\n\n:::\n\n```{.r .cell-code}\n(3.351 + 11.724) / (11.724 + 3.351 + 28.234)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.3480801\n```\n\n\n:::\n:::\n\n\n#### Julia\n\nIn Julia, the ICC for a three level model is also easiest to estimate \"by hand\".\n\n\n::: {.cell}\n\n```{.julia .cell-code}\nusing Tables, MixedModels, StatFiles, DataFrames, CategoricalArrays, DataFramesMeta\n\ndfL = DataFrame(load(\"simulated_multilevel_longitudinal_data.dta\"))\n```\n:::\n\n::: {.cell}\n\n```{.julia .cell-code}\n@transform!(dfL, :country = categorical(:country))\n```\n:::\n\n::: {.cell}\n\n```{.julia .cell-code}\n\nm0L = fit(MixedModel, @formula(outcome ~ \n                                 (1 | country) + \n                                 (1 | id)), dfL)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by maximum likelihood\n outcome ~ 1 + (1 | country) + (1 | id)\n    logLik   -2 logLik      AIC         AICc        BIC     \n -29058.2592  58116.5184  58124.5184  58124.5229  58152.9384\n\nVariance components:\n            Column   Variance Std.Dev.\nid       (Intercept)  11.72401 3.42403\ncountry  (Intercept)   3.23190 1.79775\nResidual              28.23426 5.31359\n Number of obs: 9000; levels of grouping factors: 3000, 30\n\n  Fixed-effects parameters:\n──────────────────────────────────────────────────\n               Coef.  Std. Error       z  Pr(>|z|)\n──────────────────────────────────────────────────\n(Intercept)  53.3777    0.338785  157.56    <1e-99\n──────────────────────────────────────────────────\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.julia .cell-code}\n\n3.23190 / (11.72401 + 3.23190 + 28.23426)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0.07482952718176382\n```\n\n\n:::\n\n```{.julia .cell-code}\n\n(3.23190 + 11.72401) / (11.72401 + 3.23190 + 28.23426)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0.34628041519632824\n```\n\n\n:::\n:::\n\n\n:::\n\n### Interpretation\n\nEach software suggests that almost 8% of the variation in the outcome is within time points for different individuals within the same country, while almost 35% of the variation in the outcome is within time points for the same individual within the same country. \n\n\n\n",
    "supporting": [
      "unconditional-multilingual_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}