{
  "hash": "c1a6ba8de8935531913ec8da0d1f407c",
  "result": {
    "engine": "knitr",
    "markdown": "# Multilevel Logistic Regression\n\n\n\n::: {.cell}\n\n:::\n\n\n\nBelow, I detail the procedure for multilevel logistic regression models in Stata and R. \n\n## The Data\n\nThe data employed in these examples are the cross-sectional data described in @sec-data.\n\n## The Equation\n\nTo explain statistical syntax for Stata and R, I consider the general case of a multilevel model with *categorical* dependent variable `y`, independent variables `x` and `z`, clustering variable `group`, and a random slope for `x`. *i* is the index for the person, while *j* is the index for the group.\n\n$$\\ln\\Big(\\frac{p(y)}{1-p(y)}\\Big) = \\beta_0 + \\beta_1 x_{ij} + \\beta_2 z_{ij} + u_{0j}$$ {#eq-MLMsimple-logistic}\n\n::: {.callout-caution collapse=\"false\"}\n### Correlated and Uncorrelated Random Effects in Logistic Regression\n\nThe reader is referred to the discussion of correlated and uncorrelated random effects in [Section @sec-correlated-uncorrelated]\n:::\n\n::: {.panel-tabset group=\"language\"}\n\n### Stata\n\nIn Stata `mixed`, the syntax for a multilevel model of the form described in @eq-MLMsimple-logistic is:\n\n\n\n::: {.cell}\n\n```{.stata .cell-code}\nmelogit y x z || group: \n\n```\n:::\n\n\n\n### R\n\nIn R `lme4`, the syntax for a multilevel model of the form described in @eq-MLMsimple-logistic is:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\n\nglmer(y ~ x + z + (1 | group), data = ...)\n```\n:::\n\n\n:::\n\n## Run Models\n\n::: {.callout-caution}\n### Less Variation In Logistic Than Linear Models\n\nNote that in *logistic* regression models, there is less variation to work with--due to the fact that the outcome is `1/0`, than there is in *linear* models. Therefore, in the models below, I do not attempt to estimate a random slope in addition to a random intercept, as I do in [Section @sec-crosssectional].\n:::\n\n::: {.panel-tabset group=\"language\"}\n\n### Stata\n\n#### Get The Data \n\n\n\n::: {.cell collectcode='true'}\n\n```{.stata .cell-code}\n\nuse simulated_multilevel_data.dta\n\ngenerate outcome_category = outcome > 52 // dichotomous outcome\n\n```\n:::\n\n\n\n#### Run The Model\n\nAs suggested in @eq-MLMsimple-logistic, odds ratios are obtained by exponentiating the $\\beta$ coefficients: $e^{\\beta}$. Stata provides the odds ratios automatically with option `, or`.\n\n\n\n::: {.cell}\n\n```{.stata .cell-code}\nmelogit outcome_category warmth physical_punishment i.identity i.intervention HDI || /// \ncountry:, or\n\n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFitting fixed-effects model:\n\nIteration 0:  Log likelihood = -1965.6466  \nIteration 1:  Log likelihood = -1963.7805  \nIteration 2:  Log likelihood = -1963.7791  \nIteration 3:  Log likelihood = -1963.7791  \n\nRefining starting values:\n\nGrid node 0:  Log likelihood = -1908.9697\n\nFitting full model:\n\nIteration 0:  Log likelihood = -1908.9697  (not concave)\nIteration 1:  Log likelihood =  -1903.703  \nIteration 2:  Log likelihood = -1902.2851  \nIteration 3:  Log likelihood = -1901.3176  \nIteration 4:  Log likelihood = -1901.2662  \nIteration 5:  Log likelihood = -1901.2661  \n\nMixed-effects logistic regression               Number of obs     =      3,000\nGroup variable: country                         Number of groups  =         30\n\n                                                Obs per group:\n                                                              min =        100\n                                                              avg =      100.0\n                                                              max =        100\n\nIntegration method: mvaghermite                 Integration pts.  =          7\n\n                                                Wald chi2(5)      =     219.75\nLog likelihood = -1901.2661                     Prob > chi2       =     0.0000\n-------------------------------------------------------------------------------------\n   outcome_category | Odds ratio   Std. err.      z    P>|z|     [95% conf. interval]\n--------------------+----------------------------------------------------------------\n             warmth |   1.292603   .0278565    11.91   0.000     1.239142     1.34837\nphysical_punishment |   .7524276   .0222773    -9.61   0.000     .7100077     .797382\n         1.identity |   .9517262   .0748541    -0.63   0.529     .8157636     1.11035\n     1.intervention |   1.191581   .0940459     2.22   0.026     1.020803    1.390929\n                HDI |   .9990491   .0061371    -0.15   0.877     .9870928     1.01115\n              _cons |   .9115548   .3901774    -0.22   0.829     .3939478    2.109244\n--------------------+----------------------------------------------------------------\ncountry             |\n          var(_cons)|   .2897697   .0880892                      .1596945    .5257944\n-------------------------------------------------------------------------------------\nNote: Estimates are transformed only in the first equation to odds ratios.\nNote: _cons estimates baseline odds (conditional on zero random effects).\nLR test vs. logistic model: chibar2(01) = 125.03      Prob >= chibar2 = 0.0000\n```\n\n\n:::\n:::\n\n\n\n### R\n\n#### Get The Data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(haven)\n\ndf <- read_dta(\"simulated_multilevel_data.dta\")\n\ndf$outcome_category <- 0 # initialize to 0\n\ndf$outcome_category[df$outcome > 52] <- 1 # dichotomous outcome\n```\n:::\n\n\n\n#### Change Some Variables To Categorical\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf$identity <- factor(df$identity)\n\ndf$intervention <- factor(df$intervention)\n```\n:::\n\n\n\n#### Run The Model\n\n::: {.callout-caution collapse=\"false\"}\n`lme4` does not directly provide p values in results, because of some disagreement over exactly how these p values should be calculated. Therefore, in this Appendix, I also call library `lmerTest` to provide p values for `lme4` results.\n:::\n\n::: {.callout-tip}\nR prefers to use scientific notation when possible. I find that the use of scientific notation can be confusing in reading results. I turn off scientific notation by setting a penalty for its use:  `options(scipen = 999)`.  \n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4) \n\nlibrary(lmerTest)\n\noptions(scipen = 999) \n\nfit3 <- glmer(outcome_category ~ warmth + physical_punishment + \n                identity + intervention + HDI +\n                (1 | country),\n              family = binomial(link = \"logit\"),\n              data = df)\n\nsummary(fit3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: outcome_category ~ warmth + physical_punishment + identity +  \n    intervention + HDI + (1 | country)\n   Data: df\n\n     AIC      BIC   logLik deviance df.resid \n  3816.6   3858.7  -1901.3   3802.6     2993 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.0109 -0.8798  0.4369  0.8428  2.8223 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n country (Intercept) 0.2894   0.5379  \nNumber of obs: 3000, groups:  country, 30\n\nFixed effects:\n                      Estimate Std. Error z value            Pr(>|z|)    \n(Intercept)         -0.0926371  0.4277643  -0.217              0.8286    \nwarmth               0.2566693  0.0215443  11.914 <0.0000000000000002 ***\nphysical_punishment -0.2844595  0.0295990  -9.610 <0.0000000000000002 ***\nidentity1           -0.0494765  0.0786286  -0.629              0.5292    \nintervention1        0.1752879  0.0789030   2.222              0.0263 *  \nHDI                 -0.0009513  0.0061388  -0.155              0.8769    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) warmth physc_ idntt1 intrv1\nwarmth      -0.158                            \nphyscl_pnsh -0.170 -0.082                     \nidentity1   -0.086 -0.014  0.002              \ninterventn1 -0.102  0.055  0.006 -0.020       \nHDI         -0.930 -0.007  0.012 -0.001  0.004\n```\n\n\n:::\n:::\n\n\n\n#### Calculate Odds Ratios\n\nR requires one to use a bit of extra syntax to extract the odds ratios. As suggested in @eq-MLMsimple-logistic, odds ratios are obtained by exponentiating the $\\beta$ coefficients: $e^{\\beta}$.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp(fixef(fit3))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        (Intercept)              warmth physical_punishment           identity1 \n          0.9115242           1.2926176           0.7524208           0.9517275 \n      intervention1                 HDI \n          1.1915893           0.9990492 \n```\n\n\n:::\n:::\n\n\n\n:::\n\n",
    "supporting": [
      "logistic-multilingual_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}