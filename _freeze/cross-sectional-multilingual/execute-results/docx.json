{
  "hash": "7d06e6b1d0bf481daee75448408870d2",
  "result": {
    "engine": "knitr",
    "markdown": "# Cross Sectional Multilevel Models {#sec-crosssectional}\n\n\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n\n\n## The Equation\n\nRecall the general model of @eq-MLMsimple, and the syntax outlined in @sec-syntax. Below in @eq-MLMsubstantive, we consider a more substantive example.\n\n$$\\text{outcome}_{ij}= \\beta_0 + \\beta_1 \\text{warmth}_{ij} +$$ {#eq-MLMsubstantive}\n\n$$\\beta_2 \\text{physical punishment}_{ij} +$$\n\n$$\\beta_3 \\text{identity}_{ij} + \\beta_4 \\text{intervention}_{ij} + \\beta_5 \\text{HDI}_{j} +$$\n\n$$u_{0j} + u_{1j} \\times \\text{warmth}_{ij} + e_{ij}$$ \n\n## Correlated and Uncorrelated Random Effects {#sec-correlated-uncorrelated}\n\nConsider the covariance matrix of random effects (e.g. $u_{0j}$ and $u_{1j}$). In @eq-varcovar the covariances of the random effects are constrained to be zero.\n\n$$\\begin{bmatrix}\nvar(u_{0j}) & 0 \\\\\n0 & var(u_{1j}) \n\\end{bmatrix}$$ {#eq-varcovar}\n\nAs discussed in the Chapter on multilevel models with cross-sectional data, however, one can consider a multilevel model in which the random effects are correlated, as is the case in @eq-varcovaruns.\n\n$$\\begin{bmatrix}\nvar(u_{0j}) & cov(u_{0j}, u_{1j}) \\\\\ncov(u_{0j}, u_{1j}) & var(u_{1j}) \n\\end{bmatrix}$$ {#eq-varcovaruns}\n\nProcedures for estimating models with uncorrelated and correlated random effects are detailed below [@StataCorp2023; @JSSv067i01; @MixedModels].\n\n-------------------------------------------------------------\nSoftware    Uncorrelated          Correlated\n            Random                Random\n            Effects               Effects\n----------- --------------------- ---------------------------\nStata       default               add option: `, cov(uns)`\n\nR           separate random       separate random \n            effects from          effects from\n            grouping variable     grouping variable\n            with `||`             with `|`\n\nJulia       separate terms        separate random \n            for each random       effects from\n            effect e.g.           grouping variable\n            `(1 | group) +`       with `|`.\n            `(0 + x | group)`\n-------------------------------------------------------------\n\n: Correlated and Uncorrelated Random Effects {#tbl-REs}\n\nAll models in the examples below are run with *uncorrelated* random effects, but could just as easily be run with *correlated* random effects. \n\n## Run The Models\n\n::: {.callout-warning}\n### Continuous and Categorical Variables\n\nStatistically--as noted in the main text--it is important to be clear on whether independent variables in one's model are continuous or categorical. *Continuous* variables can be entered straightforwardly into statistical syntax. *Categorical* variables, on the other hand usually require specific attention in statistical software. In Stata, categorical variables are indicated in a statistical model by prefixing them with an `i.`. In R, categorical variables are distinguished by making them into factors e.g. `x <- factor(x)`. In Julia, categorical variables are created by using the `@transform` syntax detailed below.\n:::\n\n::: {.panel-tabset group=\"language\"}\n\n### Stata\n\n#### Get The Data \n\n\n\n\n\n\n\n\n::: {.cell collectcode='true'}\n\n```{.stata .cell-code}\n\nuse simulated_multilevel_data.dta\n\n```\n:::\n\n\n\n\n\n\n\n\n#### Run The Model\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.stata .cell-code}\nmixed outcome warmth physical_punishment i.identity i.intervention HDI || /// \ncountry: warmth\n\n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPerforming EM optimization ...\n\nPerforming gradient-based optimization: \nIteration 0:  Log likelihood = -9626.6279  \nIteration 1:  Log likelihood =  -9626.607  \nIteration 2:  Log likelihood =  -9626.607  \n\nComputing standard errors ...\n\nMixed-effects ML regression                          Number of obs    =  3,000\nGroup variable: country                              Number of groups =     30\n                                                     Obs per group:\n                                                                  min =    100\n                                                                  avg =  100.0\n                                                                  max =    100\n                                                     Wald chi2(5)     = 334.14\nLog likelihood =  -9626.607                          Prob > chi2      = 0.0000\n\n-------------------------------------------------------------------------------------\n            outcome | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]\n--------------------+----------------------------------------------------------------\n             warmth |   .8345368   .0637213    13.10   0.000     .7096453    .9594282\nphysical_punishment |  -.9916657   .0797906   -12.43   0.000    -1.148052   -.8352791\n         1.identity |  -.3004767   .2170295    -1.38   0.166    -.7258466    .1248933\n     1.intervention |   .6396427   .2174519     2.94   0.003     .2134448    1.065841\n                HDI |   -.003228   .0199257    -0.16   0.871    -.0422817    .0358256\n              _cons |   51.99991   1.371257    37.92   0.000      49.3123    54.68753\n-------------------------------------------------------------------------------------\n\n------------------------------------------------------------------------------\n  Random-effects parameters  |   Estimate   Std. err.     [95% conf. interval]\n-----------------------------+------------------------------------------------\ncountry: Independent         |\n                 var(warmth) |   .0227504   .0257784      .0024689    .2096436\n                  var(_cons) |   2.963975   .9737647      1.556777    5.643163\n-----------------------------+------------------------------------------------\n               var(Residual) |   34.97499   .9097109      33.23668    36.80422\n------------------------------------------------------------------------------\nLR test vs. linear model: chi2(2) = 205.74                Prob > chi2 = 0.0000\n\nNote: LR test is conservative and provided only for reference.\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n### R\n\n#### Get The Data\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(haven)\n\ndf <- read_dta(\"simulated_multilevel_data.dta\")\n```\n:::\n\n\n\n\n\n\n\n\n#### Change Some Variables To Categorical\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf$identity <- factor(df$identity)\n\ndf$intervention <- factor(df$intervention)\n```\n:::\n\n\n\n\n\n\n\n\n\n#### Run The Model\n\n::: {.callout-caution collapse=\"false\"}\n`lme4` does not directly provide p values in results, because of some disagreement over exactly how these p values should be calculated. Therefore, in this Appendix, I also call library `lmerTest` to provide p values for `lme4` results.\n:::\n\n::: {.callout-tip}\nR prefers to use scientific notation when possible. I find that the use of scientific notation can be confusing in reading results. I turn off scientific notation by setting a penalty for its use:  `options(scipen = 999)`.  \n:::\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4) \n\nlibrary(lmerTest)\n\noptions(scipen = 999) \n\nfit1 <- lmer(outcome ~ warmth + physical_punishment + \n               identity + intervention + HDI +\n               (1 + warmth || country),\n             data = df)\n\nsummary(fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: outcome ~ warmth + physical_punishment + identity + intervention +  \n    HDI + (1 + warmth || country)\n   Data: df\n\nREML criterion at convergence: 19268.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.9774 -0.6563  0.0186  0.6645  3.6730 \n\nRandom effects:\n Groups    Name        Variance Std.Dev.\n country   (Intercept)  3.19120 1.786   \n country.1 warmth       0.02464 0.157   \n Residual              35.01779 5.918   \nNumber of obs: 3000, groups:  country, 30\n\nFixed effects:\n                       Estimate  Std. Error          df t value\n(Intercept)           52.011324    1.414976   30.293141  36.758\nwarmth                 0.834562    0.064250   41.896457  12.989\nphysical_punishment   -0.991893    0.079845 2968.012381 -12.423\nidentity1             -0.300354    0.217179 2970.108153  -1.383\nintervention1          0.639060    0.217603 2971.186718   2.937\nHDI                   -0.003394    0.020598   27.592814  -0.165\n                                Pr(>|t|)    \n(Intercept)         < 0.0000000000000002 ***\nwarmth              0.000000000000000277 ***\nphysical_punishment < 0.0000000000000002 ***\nidentity1                        0.16678    \nintervention1                    0.00334 ** \nHDI                              0.87030    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) warmth physc_ idntt1 intrv1\nwarmth      -0.124                            \nphyscl_pnsh -0.149 -0.003                     \nidentity1   -0.072 -0.012 -0.003              \ninterventn1 -0.082  0.034  0.022 -0.018       \nHDI         -0.943 -0.006  0.009 -0.001  0.000\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n### Julia\n\n#### Get The Data\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.julia .cell-code}\nusing Tables, MixedModels, StatFiles, DataFrames, CategoricalArrays, DataFramesMeta\n\ndf = DataFrame(load(\"simulated_multilevel_data.dta\"))\n```\n:::\n\n\n\n\n\n\n\n\n#### Change Some Variables To Categorical\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.julia .cell-code}\n@transform!(df, :country = categorical(:country))\n\n@transform!(df, :identity = categorical(:identity))\n\n@transform!(df, :intervention = categorical(:intervention))\n```\n:::\n\n\n\n\n\n\n\n\n#### Run The Model\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.julia .cell-code}\n\nm1 = fit(MixedModel, @formula(outcome ~ warmth + physical_punishment + \n               identity + intervention + HDI +\n               (1 | country) +\n               (0 + warmth | country)), df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by maximum likelihood\n outcome ~ 1 + warmth + physical_punishment + identity + intervention + HDI + (1 | country) + (0 + warmth | country)\n   logLik   -2 logLik     AIC       AICc        BIC    \n -9626.6070 19253.2140 19271.2140 19271.2742 19325.2713\n\nVariance components:\n            Column    Variance Std.Dev.   Corr.\ncountry  (Intercept)   2.963849 1.721583\n         warmth        0.022756 0.150852   .  \nResidual              34.974984 5.913965\n Number of obs: 3000; levels of grouping factors: 30\n\n  Fixed-effects parameters:\n─────────────────────────────────────────────────────────────\n                          Coef.  Std. Error       z  Pr(>|z|)\n─────────────────────────────────────────────────────────────\n(Intercept)          51.9999      1.37124     37.92    <1e-99\nwarmth                0.834537    0.0637228   13.10    <1e-38\nphysical_punishment  -0.991665    0.0797906  -12.43    <1e-34\nidentity: 1.0        -0.300475    0.217029    -1.38    0.1662\nintervention: 1.0     0.639641    0.217452     2.94    0.0033\nHDI                  -0.0032286   0.0199255   -0.16    0.8713\n─────────────────────────────────────────────────────────────\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n\n## Interpretation\n\nModels suggest that parental warmth is associated with increases in the beneficial outcome, while physical punishment is associated with decreases in the beneficial outcome. The intervention is associated with increases in the outcome. There is insufficient evidence that either identity group or the Human Development Index are associated with the outcome.\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}