{
  "hash": "272bf2e06baf5f1dc1e9712247592f86",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Multilevel Multilingual\"\n---\n\n\n## Introduction\n\nBelow, I describe the use of [Stata](https://www.stata.com/), [R](https://www.r-project.org/), and [Julia](https://www.julialang.org/) to estimate multilevel models. Because this document is built by [`Quarto`](https://quarto.org/), I describe calling these programs from within a `Quarto` environment. However, each piece of software could be used individually and separately.\n\n## The Data\n\nThe examples below use the `simulated_multilevel_data.dta` file from [*Multilevel Thinking*](https://agrogan1.github.io/multilevel-thinking/simulated-multi-country-data.html). Here is a [direct link](https://github.com/agrogan1/multilevel-multilingual/raw/main/simulated_multilevel_data.dta) to download the data.\n\n\n::: {.cell}\n\n:::\n\n::: {#tbl-multilingual1 .cell tbl-cap='Sample of Simulated Multilevel Data'}\n::: {.cell-output-display}\n\n-------------------------------------------------------------------------------\n country   HDI   family   id    group   physical_punishment   warmth   outcome \n--------- ----- -------- ----- ------- --------------------- -------- ---------\n    1      69      1      1.1     2              2              3       59.18  \n\n    1      69      2      1.2     2              4              0       61.54  \n\n    1      69      3      1.3     1              4              4       51.87  \n\n    1      69      4      1.4     2              0              6       51.71  \n\n    1      69      5      1.5     2              3              2       55.88  \n\n    1      69      6      1.6     1              5              3       60.78  \n-------------------------------------------------------------------------------\n\n\n:::\n:::\n\n\n## The Equation\n\n$$\\text{outcome}_{ij}= \\beta_0 + \\beta_1 \\text{warmth}_{ij} + \\beta_2 \\text{physical punishment}_{ij} + \\\\ \\beta_3 \\text{group}_{ij} + \\beta_4 \\text{HDI}_{ij} + \\\\ u_{0j} + u_{1j} \\times \\text{warmth}_{ij} + e_{ij}$$ {#eq-MLMsubstantive}\n   \n## Setup \n\n::: {.panel-tabset group=\"language\"}\n\n### Stata\n\nI need to use the library `Statamarkdown` to call Stata, or I could run Stata on its own\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Statamarkdown)\n```\n:::\n\n\n### R\n\nIn R, I use the library `lme4` to run multilevel models. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4) \n```\n:::\n\n\n### Julia\n\nI need to call Julia from R.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(JuliaCall)\n\njulia_setup(JULIA_HOME = \"/Applications/Julia-1.8.app/Contents/Resources/julia/bin\")\n```\n:::\n\n\n:::\n\n## Get Data & Run Models\n\nTo explain statistical syntax for each software, I consider the more general case of a multilevel model with dependent variable `y`, independent variables `x` and `z`, clustering variable `group`, and a random slope for `x`. *i* is the index for the person, while *j* is the index for the `group`.\n\n$$y = \\beta_0 + \\beta_1 x_{ij} + \\beta_2 z_{ij} + u_{0j} + u_{1j} \\times x_{ij} + e_{ij}$$ {#eq-MLMsimple}\n\n::: {.panel-tabset group=\"language\"}\n\n### Stata\n\nIn Stata `mixed`, the syntax for a multilevel model of the form described in @eq-MLMsimple is:\n\n`mixed y x || group: x`\n\n#### Get The Data \n\n::: {.callout-tip collapse=\"true\"}\n#### Tip For Running Stata From Quarto\n\nBecause I am running Stata from inside a Quarto document, and running Stata in multiple chunks, I need to use the `collectcode=TRUE` option in the first Stata chunk. i.e. my Quarto chunk needs to begin with ````{stata, collectcode=TRUE}`\n\nSee Doug Hemken's excellent documentation on `Statamarkdown` [here](https://www.ssc.wisc.edu/~hemken/Stataworkshops/Statamarkdown/linking-code-blocks.html#linking-code-blocks-1).\n:::\n\n\n::: {.cell collectcode='true'}\n\n```{.stata .cell-code}\n\nuse simulated_multilevel_data.dta\n\n```\n:::\n\n\n#### Graph\n\n\n::: {.cell}\n\n```{.stata .cell-code}\ntwoway scatter outcome warmth, xtitle(\"warmth\") ytitle(\"outcome\") title(\"Outcome by Parental Warmth\") \n\nquietly graph export scatter.png, replace\n\n```\n:::\n\n\n![Outcome by Parental Warmth (Stata)](scatter.png){#fig-Stata}\n\n#### Run The Model\n\n\n::: {.cell}\n\n```{.stata .cell-code}\n\nmixed outcome warmth physical_punishment group HDI || country: warmth\n\n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPerforming EM optimization ...\n\nPerforming gradient-based optimization: \nIteration 0:  Log likelihood =  -9668.198  \nIteration 1:  Log likelihood = -9667.9551  \nIteration 2:  Log likelihood = -9667.9534  \nIteration 3:  Log likelihood = -9667.9533  \nIteration 4:  Log likelihood = -9667.9532  \n\nComputing standard errors ...\n\nMixed-effects ML regression                          Number of obs    =  3,000\nGroup variable: country                              Number of groups =     30\n                                                     Obs per group:\n                                                                  min =    100\n                                                                  avg =  100.0\n                                                                  max =    100\n                                                     Wald chi2(4)     = 401.26\nLog likelihood = -9667.9532                          Prob > chi2      = 0.0000\n\n-------------------------------------------------------------------------------------\n            outcome | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]\n--------------------+----------------------------------------------------------------\n             warmth |   .9616447   .0581825    16.53   0.000     .8476091     1.07568\nphysical_punishment |  -.8453802   .0798155   -10.59   0.000    -1.001816   -.6889448\n              group |   1.084344   .2200539     4.93   0.000     .6530461    1.515642\n                HDI |    .010557   .0204522     0.52   0.606    -.0295286    .0506426\n              _cons |   49.87963   1.436612    34.72   0.000     47.06392    52.69534\n-------------------------------------------------------------------------------------\n\n------------------------------------------------------------------------------\n  Random-effects parameters  |   Estimate   Std. err.     [95% conf. interval]\n-----------------------------+------------------------------------------------\ncountry: Independent         |\n                 var(warmth) |   1.83e-06   .0000173      1.76e-14    190.9774\n                  var(_cons) |   3.370262   .9633726      1.924651    5.901676\n-----------------------------+------------------------------------------------\n               var(Residual) |   36.01906   .9346936      34.23291    37.89842\n------------------------------------------------------------------------------\nLR test vs. linear model: chi2(2) = 198.01                Prob > chi2 = 0.0000\n\nNote: LR test is conservative and provided only for reference.\n```\n\n\n:::\n:::\n\n\n### R\n\nIn R `lme4`, the general syntax for a multilevel model of the form described in @eq-MLMsimple is:\n\n`lmer(y ~ x + z + (1 + x || group), data = ...)`\n\n#### Get The Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(haven)\n\ndf <- read_dta(\"simulated_multilevel_data.dta\")\n```\n:::\n\n\n#### Graph\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\nggplot(df,\n       aes(x = warmth,\n           y = outcome)) +\n  geom_point() +\n  labs(title = \"Outcome by Parental Warmth\")\n```\n\n::: {.cell-output-display}\n![Outcome by Parental Warmth (R)](index_files/figure-html/fig-R-1.png){#fig-R width=672}\n:::\n:::\n\n\n#### Run The Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 <- lmer(outcome ~ warmth + physical_punishment + \n               group + HDI +\n               (1 + warmth || country),\n             data = df)\n\nsummary(fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: outcome ~ warmth + physical_punishment + group + HDI + ((1 |  \n    country) + (0 + warmth | country))\n   Data: df\n\nREML criterion at convergence: 19350.3\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.4496 -0.6807  0.0016  0.6864  3.1792 \n\nRandom effects:\n Groups    Name        Variance  Std.Dev.\n country   (Intercept)  3.611568 1.90041 \n country.1 warmth       0.001876 0.04331 \n Residual              36.049124 6.00409 \nNumber of obs: 3000, groups:  country, 30\n\nFixed effects:\n                    Estimate Std. Error t value\n(Intercept)         49.88754    1.48203  33.662\nwarmth               0.96155    0.05875  16.367\nphysical_punishment -0.84556    0.07986 -10.588\ngroup                1.08471    0.22017   4.927\nHDI                  0.01044    0.02116   0.493\n\nCorrelation of Fixed Effects:\n            (Intr) warmth physc_ group \nwarmth      -0.126                     \nphyscl_pnsh -0.135 -0.025              \ngroup       -0.218 -0.010 -0.019       \nHDI         -0.925 -0.006  0.008 -0.001\n```\n\n\n:::\n:::\n\n\n### Julia\n\nIn Julia `MixedModels`, the general syntax for a multilevel model of the form described in @eq-MLMsimple is:\n\n`fit(MixedModel, @formula(y ~ x + z + (1 + x | group)), data)`\n\n#### Load The Needed Packages And Load The Data\n\n\n::: {.cell}\n\n```{.julia .cell-code}\nusing Tables, MixedModels, StatFiles, DataFrames, CategoricalArrays, DataFramesMeta\n\ndf = DataFrame(load(\"simulated_multilevel_data.dta\"))\n```\n:::\n\n\n#### Graph\n\n\n::: {.cell}\n\n```{.julia .cell-code}\nusing StatsPlots\n\n@df df scatter(:outcome, :warmth, \n               title = \"Outcome by Parental Warmth\",\n               ylabel = \"outcome\",\n               xlabel = \"parental warmth\")\n```\n\n::: {.cell-output-display}\n![Outcome by Parental Warmth (Julia)](index_files/figure-html/fig-Julia-J1.png){#fig-Julia width=300}\n:::\n:::\n\n\n#### Change Country To Categorical\n\n\n::: {.cell}\n\n```{.julia .cell-code}\n@transform!(df, :country = categorical(:country))\n```\n:::\n\n\n#### Run The Model\n\n\n::: {.cell}\n\n```{.julia .cell-code}\n\nm1 = fit(MixedModel, @formula(outcome ~ warmth + physical_punishment + \n               group + HDI +\n               (1 + warmth | country)), df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by maximum likelihood\n outcome ~ 1 + warmth + physical_punishment + group + HDI + (1 + warmth | country)\n   logLik   -2 logLik     AIC       AICc        BIC    \n -9667.9392 19335.8783 19353.8783 19353.9385 19407.9357\n\nVariance components:\n            Column    Variance   Std.Dev.   Corr.\ncountry  (Intercept)   3.2369484 1.7991521\n         warmth        0.0001080 0.0103903 +1.00\nResidual              36.0187144 6.0015593\n Number of obs: 3000; levels of grouping factors: 30\n\n  Fixed-effects parameters:\n─────────────────────────────────────────────────────────────\n                          Coef.  Std. Error       z  Pr(>|z|)\n─────────────────────────────────────────────────────────────\n(Intercept)          49.9018      1.43435     34.79    <1e-99\nwarmth                0.961545    0.0582135   16.52    <1e-60\nphysical_punishment  -0.845389    0.0798149  -10.59    <1e-25\ngroup                 1.08524     0.220055     4.93    <1e-06\nHDI                   0.0101984   0.0204401    0.50    0.6178\n─────────────────────────────────────────────────────────────\n```\n\n\n:::\n:::\n\n\n:::\n\n",
    "supporting": [
      "index_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}